## 📌 시스템 콜

### OS-001

시스템 콜이 무엇인지 설명해 주세요.

- 시스템 콜(System Call)은 **유저 프로그램이 커널 기능을 요청하기 위해 제공되는 인터페이스**

- 프로그램은 하드웨어에 직접 접근할 수 없기 때문에, I/O, 파일 접근, 프로세스 생성 등은 모두 시스템 콜을 통해 커널이 대신 수행한다.

### OS-002

우리가 사용하는 시스템 콜의 예시를 들어주세요.

- 파일 작업: `open()`, `read()`, `write()`, `close()`
- 프로세스 관리: `fork()`, `exec()`, `wait()`, `exit()`
- 메모리 관리: `mmap()`, `brk()`
- 네트워크: `socket()`, `connect()`, `send()`, `recv()`
- 기타: `ioctl()`, `kill()`

### OS-003

시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.

1. 유저 모드에서 시스템 콜 라이브러리(glibc 등) 호출
2. **시스템 콜 번호** 설정
3. trap 또는 syscall 명령을 통해 **커널 모드로 전환**
4. 커널이 시스템 콜 테이블에서 해당 번호에 해당하는 함수 실행
5. 작업 완료 후 다시 **유저 모드로 복귀**
6. 결과를 유저 프로그램에 반환

### OS-004

시스템 콜의 유형에 대해 설명해 주세요.

- **프로세스 제어**: fork, exec, exit
- **파일 제어**: open, read, write
- **디바이스 조작**: ioctl
- **정보 유지**: getpid, time
- **통신(IPC)**: pipe, shared memory, socket

### OS-005

운영체제의 Dual Mode 에 대해 설명해 주세요.

- 운영체제는 **유저 모드(User Mode)** 와 **커널 모드(Kernel Mode)** 두 가지 실행 모드를 가진다.
  - 유저 모드: 제한된 명령만 실행 가능, 직접 하드웨어 접근 불가
  - 커널 모드: 모든 명령 실행 가능, privileged instruction 수행 가능

### OS-006

왜 유저모드와 커널모드를 구분해야 하나요?

- 사용자 프로그램이 시스템 전체를 망가뜨리는 것을 방지
- 보안 유지 (메모리/디스크/네트워크 접근 통제)
- 프로세스 간 보호
- 하드웨어 자원 보호
  → **안정성과 보안 확보를 위해서 필수**

### OS-007

서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?

- 시스템 콜마다 고유한 **시스템 콜 번호(System call number)**가 존재하여 커널은 넘겨받은 번호를 기반으로 **시스템 콜 테이블에서 해당 핸들러를 실행**

---

## 📌 인터럽트

### OS-008

인터럽트가 무엇인지 설명해 주세요.

- 인터럽트(Interrupt)는 **CPU가 명령을 실행하는 도중, 외부 또는 내부에서 발생한 사건을 처리하기 위해 현재 작업을 중단시키는 메커니즘**으로, 프로그램 흐름을 바꾸어 커널이 해당 작업을 우선 처리하게 한다.

### OS-009

인터럽트는 어떻게 처리하나요?

1. 인터럽트 발생
2. CPU는 현재 작업 상태(문맥)를 저장
3. 인터럽트 벡터(Interrupt Vector)를 조회해 ISR(Interrupt Service Routine)으로 점프
4. 커널이 ISR을 실행하여 인터럽트 처리
5. 처리 완료 후 저장해둔 문맥 복원
6. 원래 실행하던 프로그램으로 복귀

→ 이 과정은 하드웨어와 커널이 함께 담당

### OS-010

Polling 방식에 대해 설명해 주세요.

- Polling은 CPU가 주기적으로 장치 상태를 직접 확인하여 작업이 필요한지 판단하는 방식
  - **장점**: 구현 간단, 인터럽트 오버헤드 없음
  - **단점**: CPU 낭비, 실시간 응답 어려움
    → 장치 이벤트가 거의 없을 때는 비효율적

인터럽트는 이벤트 기반, Polling은 반복 검사 기반

### OS-011

HW / SW 인터럽트에 대해 설명해 주세요.

- 하드웨어 인터럽트

  - 외부 장치에서 발생
  - 예: 키보드 입력, 디스크 I/O 완료, 네트워크 패킷 도착
  - CPU 외부의 하드웨어가 interrupt line을 통해 발생시키는 신호

- 소프트웨어 인터럽트
  - 프로그램(사용자/OS)에서 직접 발생
  - 예: 시스템 콜, 예외(Exception: divide by zero), 트랩(Trap)
  - 소프트웨어 명령을 통해 의도적으로 인터럽트를 발생시킴

### OS-012

동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?

- 운영체제는 인터럽트 우선순위에 따라 처리 순서를 결정
  - 높은 우선순위 인터럽트 → 먼저 처리
  - 낮은 우선순위 인터럽트는 대기
  - 일부 시스템은 인터럽트 중에도 더 높은 우선순위 인터럽트를 다시 받을 수 있는 **Nested Interrupt** 구조 지원
    → 결국 우선순위 + 중첩 가능 여부로 동시 발생 문제를 해결한다.

---

## 📌 프로세스

### OS-013

프로세스가 무엇인가요?

- 프로세스는 실행 중인 프로그램을 의미한다.
- 코드 + 데이터 + 스택 + 레지스터 + PCB 등 **실행에 필요한 모든 정보**를 포함하며, 운영체제로부터 CPU·메모리 등의 자원을 할당받는다.

### OS-014

프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.

- 프로그램: 파일에 저장된 명령어 집합(정적인 상태)
- 프로세스: 실행 중인 프로그램(동적인 상태), 독립된 메모리 공간/자원 보유
- 스레드: 프로세스 내 실행 단위, 코드·데이터·힙 공유, 스택만 독립

### OS-015

PCB가 무엇인가요?

- PCB(Process Control Block)는 프로세스의 모든 실행 정보를 저장한 커널 자료구조
  - 프로세스 ID
  - CPU 레지스터 값
  - 프로그램 카운터
  - 스케줄링 정보
  - 메모리 정보(페이지 테이블 등)
  - 파일 핸들

### OS-016

그렇다면, 스레드는 PCB를 갖고 있을까요?

- 스레드는 **독립적인 전체 PCB는 가지지 않는다.**
- 하지만 다음 정보는 **TCB(Thread Control Block)** 형태로 갖는다:
  - 스레드 ID
  - 스택 포인터
  - 레지스터
  - 스케줄링 정보
- 프로세스 전체 정보(코드/데이터/힙/파일 디스크립터)는 공유

### OS-017

리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?

- `clone()` 시스템 콜을 이용
- `fork()` → 새로운 프로세스 생성 (주소공간 별도)
- `clone()` → 공유 정도를 flag로 지정 - 대부분의 flag(PTHREAD) 공유 시 → 스레드 생성 - 공유 없음 → 프로세스와 동일하게 동작
  → 리눅스는 프로세스·스레드 모두 “Task”로 관리한다.

### OS-018

자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?

- 자식이 먼저 죽고 부모가 wait()을 호출하지 않았을 때
  - 자식은 **Zombie Process(좀비 프로세스)** 가 됨
  - init(1) 프로세스가 이를 회수(reap)
- 부모 프로세스가 먼저 죽었을 때
  - 고아(Orphan) 프로세스가 됨
  - init(1) 또는 systemd가 부모가 되어 정리

### OS-019

리눅스에서, 데몬프로세스에 대해 설명해 주세요.

- **백그라운드에서 독립적으로 실행되는 프로세스**
- 터미널/사용자 세션과 분리
- init/systemd에 의해 관리
- 예: sshd, crond, systemd-journald

### OS-020

리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.

- **init(1)** 또는 최신 리눅스에서는 **systemd(1)**이다.
  - 시스템 부팅 시 가장 먼저 생성되는 유저 프로세스
  - 모든 프로세스의 최상위 부모
  - 고아 프로세스를 인수하고 관리
  - 서비스 데몬 실행 관리(systemd)

---

## 📌 프로세스 주소공간

### OS-021

프로세스 주소공간에 대해 설명해 주세요.

- 프로세스가 실행될 때 운영체제가 부여하는 **논리적 메모리 구조**이다.
- 일반적인 구성:
  1. **Text(코드) 영역** – 실행 명령어 저장
  2. **Data 영역** – 전역 변수, static 변수 (초기화 O)
  3. **BSS 영역** – 전역 변수, static 변수 (초기화 X → 0으로 초기화)
  4. **Heap 영역** – 동적 메모리 (malloc/new)
  5. **Stack 영역** – 함수 호출, 지역 변수, 리턴 주소 등

### OS-022

초기화 하지 않은 변수들은 어디에 저장될까요?

- 초기화되지 않은 전역/정적 변수는 **BSS 영역**에 들어간다. BSS는 OS가 0으로 초기화하여 메모리에 배치한다.
- BSS(Block Started by Symbol): 초기화되지 않은 전역 변수 · static 변수를 저장하는 메모리 영역

### OS-023

일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?

- Stack은 **프로세스 생성 시 고정된 최대 크기(limit)** 가 있다.
- Heap은 **필요할 때 동적으로 증가**할 수 있지만 시스템 메모리/제약에 의해 제한된다.

### OS-024

Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?

- 스택이 힙보다 빠르다
- Stack은 **연속적인 메모리 구조 + LIFO**라 CPU 캐시 효율이 높다
- Heap은 메모리 할당자가 관리하며 **동적 탐색/할당 오버헤드**가 발생

### OS-025

다음과 같이 공간을 분할하는 이유가 있을까요?

(코드 / 데이터 / BSS / 힙 / 스택)

- 보호 및 안정성: 실행 코드(Text)는 읽기 전용
- 구조적 관리: 전역 변수, 동적 메모리, 스택 등을 분리해 효율적 관리
- 보안 강화: Stack Overflow 방지(Stack Guard 등)
- 메모리 효율성: 영역별 성장 방향을 분리해 충돌 최소화

### OS-026

스레드의 주소공간은 어떻게 구성되어 있을까요?

- 코드/데이터/힙은 **프로세스의 다른 스레드들과 공유**
- 스레드마다 **독립적인 스택(Stack)** 을 갖는다
- 커널 스레드는 커널 스택도 각각 보유

→ 공유하며 독립적으로 동작하는 구조

### OS-027

"스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.

- 스택 영역 = 자료구조 스택과 동일
  - 함수 호출 시 push
  - 함수 종료 시 pop
  - LIFO 구조
- 힙 영역 != 자료구조 힙
  - 운영체제/할당자가 관리하는 동적 메모리 풀
  - 내부 동작은 다름

### OS-028

IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요?

- 공유 메모리는 Heap 영역에 매핑된다
- 이유:
  - 동적 크기
  - 여러 프로세스가 동일 물리 메모리를 매핑해야 함
  - mmap() 등을 통해 VA ↔ PA 매핑을 구성

### OS-029

스택과 힙영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요?

- 스택: 프로세스 생성 시 OS가 기본 크기 결정 (ulimit -s로 변경 가능)
- 힙: 실행 중 필요에 따라 증가 (brk, mmap)
- 사용자 관점: 스택/힙 limit을 환경에 따라 조절 가능

---

## 📌 CPU 스케줄링

### OS-030

단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.

- 단기: Ready Queue에서 다음 실행할 프로세스를 선택하여 빈번하게 실행 - 실질적 스케줄링
- 중기: 메모리가 부족할 때 프로세스를 메모리에서 디스크로 스왑 아웃, 필요 시 스왑 인
- 장기: 어떤 프로그램을 메모리에 적재할지 결정하여 Job -> Ready Queue로 이동시켜 시스템 전체 멀티프로그래밍 정도 조절

### OS-031

현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?

- **단기 스케줄러**: 항상 존재
- **중기 스케줄러**: 거의 사용하지 않음 (스왑 비중 감소)
- **장기 스케줄러**: Batch 시스템에서는 사용하지만, 일반적인 Linux/Windows에서는 사실상 OS가 모든 Job을 메모리에 로드하므로 역할이 미미함

### OS-032

프로세스의 스케쥴링 상태에 대해 설명해 주세요.

1. **New** – 생성 중
2. **Ready** – CPU 할당 대기
3. **Running** – CPU 실행 중
4. **Waiting/Blocked** – I/O 등 이벤트 기다림
5. **Terminated** – 종료 상태

### OS-033

preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?

- 둘 모두 동일한 **스케줄링 상태(Ready, Running, Blocked)** 를 가지고 상태 전환 방식이 다를 뿐이다.
  - Preemptive: Running → Ready (강제 중단) 발생 가능
  - Non-preemptive: Running → Ready 전환 없음

### OS-034

Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?

- 메모리가 부족하면 OS는 해당 프로세스를 Swapped Out 상태로 내보낸다.
  - 실제 상태: Blocked/Waiting + Swap out
  - Ready Queue에는 존재하지 않음
  - 메모리가 확보되면 다시 Swap in되어 Ready 상태 복귀
    → 현대 OS에서는 “중기 스케줄링” 역할이 축소되었지만 개념적으로는 동일하다.

---

## 📌 컨텍스트 스위칭

### OS-035

컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?

- 컨텍스트 스위칭(Context Switching)은 **CPU가 현재 실행 중인 프로세스/스레드의 상태를 저장하고, 다른 프로세스/스레드의 상태를 복원하는 과정**

1. 현재 실행 중인 프로세스의 레지스터 값 저장 (PC, SP, general registers 등)
2. PCB 또는 TCB에 저장
3. 새로 실행할 프로세스의 레지스터 값/메모리 맵을 PCB에서 복원
4. CPU가 해당 프로세스를 실행하도록 점프

→ 이 오버헤드 때문에 스위칭은 빈번할수록 성능이 떨어짐.

### OS-036

프로세스와 스레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?

- 프로세스 컨텍스트 스위칭
  - 주소공간 변경 필요
  - 페이지 테이블 변경
  - 캐시 미스 증가 가능
  - 무거운 스위칭
- 스레드 컨텍스트 스위칭
  - 같은 프로세스 내부라 주소공간 공유
  - Stack Pointer, PC, 레지스터만 바꾸면 됨
  - page table 변화 없음
  - 가벼운 스위칭

### OS-037

컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?

- 레지스터 값 (PC, SP, general registers)
- 프로그램 카운터
- 프로세스 상태
- CPU Scheduling 정보
- 메모리 매핑 정보
  이 모든 정보는 **PCB(Process Control Block)** 에 저장되며, PCB 자체는 **커널 공간(Kernel Stack)** 에 저장된다.

### OS-038

컨텍스트 스위칭은 언제 일어날까요?

1. **타임 슬라이스(Time quantum) 만료 → Preemptive Scheduling**
2. **I/O 발생** → Running → Blocked 상태 전환
3. **더 높은 우선순위 프로세스 도착**
4. **프로세스 종료(exit)**
5. **Interrupt 발생** (I/O 완료 등)
6. **시스템 콜 호출**(경우에 따라)
   → CPU가 다음 실행 대상을 선택해야 하는 순간이면 언제든 발생한다.

---

## 📌 스케줄링 알고리즘

### OS-039

프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?

- **FCFS (First Come First Served)**: 가장 먼저 도착한 프로세스를 먼저 처리하는 비선점형(Non-Preemptive) 방식
- **SJF (Shortest Job First)**: 실행 시간이 가장 짧은 프로세스를 먼저 수행하는 비선점형 방식
- **SRTF (Shortest Remaining Time First)**: SJF의 선점형(Preemptive) 버전 - 더 짧은 작업이 새로 도착하면 현재 실행 중인 작업을 중단하고 교체
- **RR (Round Robin)**: 각 프로세스에 동일한 Time Slice(퀀텀)를 주고 순환 방식으로 CPU 할당
- **Priority Scheduling (우선순위 스케줄링)**: 우선순위가 높은 프로세스를 먼저 실행하는 방식
- **MLQ (Multi-Level Queue)**: 프로세스를 여러 **고정된 큐(우선순위 그룹)**로 나누어 스케줄링
- **MLFQ (Multi-Level Feedback Queue)**: CPU를 많이 쓰면 낮은 우선순위 큐로 이동, 짧게 쓰면 높은 우선순위 유지 → 실제 사용자 체감 속도 개선

### OS-040

RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.

- 너무 짧으면
  - 컨텍스트 스위칭 과다
  - CPU 오버헤드 증가
  - 실제 작업 효율 감소
- 너무 길면
  - FCFS에 가까워짐
  - 응답시간(Response Time) 증가
  - 인터랙티브한 환경에서 사용자 경험 악화

### OS-041

싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요?

- **Priority Scheduling(우선순위 스케줄링)** 또는 **MLFQ(우선순위 기반 스케줄링 + 동적 feedback)**
- 특정 프로세스(예: 커널 데몬, 모니터링 프로세스)가 항상 CPU를 확보해야 함
- 우선순위를 높게 부여하면 Starvation 없이 안정적 실행 가능
- MLFQ는 우선순위를 동적으로 조정해 더 공정한 구조 제공

### OS-042

동시성과 병렬성의 차이에 대해 설명해 주세요.

- 동시성
  - 단일 코어에서도 **작업을 번갈아 실행하여 동시에 실행되는 것처럼 보이는 것**
  - 시간 분할(Time-sharing) 기반
  - 논리적 동시성
- 병렬성
  - 멀티코어 환경에서 **작업이 실제로 동시에 실행되는 것**
  - 물리적 동시성

### OS-043

타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?

1. **모든 프로세스를 공평하게 다루지 못하는 문제(FIFO/SJF의 단점 보완)**
2. **작업 특성을 미리 몰라도 대응 가능** (Adaptive)
3. **I/O-bound 프로세스가 기아(Starvation)에 빠지는 문제 해결**
4. **우선순위 배정 자동화**
   - CPU-bound: 우선순위 낮아짐
   - I/O-bound: 높은 우선순위 유지

→ 다양한 작업 유형을 효율적으로 처리하는 데 최적화된 알고리즘

### OS-044

FIFO 스케쥴러는 정말 쓸모가 없는 친구일까요? 어떤 시나리오에 사용하면 좋을까요?

- **Batch 작업 처리 시스템**
- 작업 시간이 모두 비슷한 환경
- 문맥전환 오버헤드가 큰 시스템
- 단순한 직렬 처리(Queue 기반)에서 예측 가능한 흐름이 필요할 때
  → 즉, “공정성보다 예측성·단순성이 중요한” 환경에서는 유효하다

### OS-045

우리는 스케줄링 알고리즘을 "프로세스" 스케줄링 알고리즘이라고 부릅니다. 스레드는 다른 방식으로 스케줄링을 하나요?

- 기본적으로 **프로세스와 스레드 모두 동일한 스케줄러**에 의해 관리된다.
- Linux 기준: “Task” 단위로 동일한 CFS 스케줄러 처리
- 스레드는 독립적인 실행 단위이므로 Ready Queue에 Task로 등록됨
  → 스케줄링 방식은 같지만, 스레드는 주소공간을 공유

### OS-046

유저 스레드와 커널 스레드의 스케쥴링 알고리즘은 똑같을까요?

- 유저 스레드: 라이브러리 수준에서 스케줄링(Pthreads, Green Thread 방식)
- 커널 스레드: OS 커널 스케줄러(CFS 등)가 직접 스케줄링

---

## 📌 프로세스 동기화 문제

### OS-047

뮤텍스와 세마포어의 차이점은 무엇인가요?

- 뮤텍스: 상호 배제를 위해 하나의 Lock만 가짐
- 세마포어: 정수 값을 통해 공유 자원 접근 허용 개수 조절

### OS-048

이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.

- 이진 세마포어
  - 소유권 없음
  - 누구나 signal() 호출 가능
  - 동기화(Event signaling) 용도로도 사용됨
- 뮤텍스
  - Lock 소유권이 중요
  - Lock을 획득한 스레드만 해제 가능
  - Critical Section 용도

### OS-049

Lock을 얻기 위해 대기하는 프로세스들은 Spin Lock 기법을 사용할 수 있습니다. 이 방법의 장단점은 무엇인가요? 단점을 해결할 방법은 없을까요?

- 장점
  - Context Switching 없음 → 매우 빠름
  - Lock이 짧은 시간만 유지될 때 유리
  - 멀티코어 환경에서 효과적
- 단점
  - CPU를 계속 소모 (Busy-waiting)
  - Lock이 길게 유지되면 오히려 성능 저하
- 해결 방법
  - **Ticket Lock** (공정성 보장)
  - **Queue Lock**(MCS lock 등)
  - 일정 시간 대기 후 Sleep 전환 → **Adaptive Spin Lock**

### OS-050

뮤텍스와 세마포어 모두 커널이 관리하기 때문에, Lock을 얻고 방출하는 과정에서 시스템 콜을 호출해야 합니다. 이 방법의 장단점이 있을까요? 단점을 해결할 수 있는 방법은 없을까요?

- **장점**

  - 커널이 관리하므로 안정적
  - 프로세스 간 동기화에 적합
  - Deadlock/priority inversion 처리 가능

- **단점**

  - 시스템 콜 호출 → 컨텍스트 스위칭 → 오버헤드
  - 사용자 스레드 간 동기화는 비효율적

- **해결책**
  - **User-level Lock** (ex: futex 기반)
    - Lock이 free일 때는 유저 모드에서 처리 → 빠름
    - 경쟁 시에만 커널 진입(futex) → 오버헤드 감소

### OS-051

Deadlock 에 대해 설명해 주세요.

- Deadlock은 두 개 이상의 프로세스가 서로 자원을 기다리며 무한 대기하는 상황

### OS-052

Deadlock 이 동작하기 위한 4가지 조건에 대해 설명해 주세요.

1. **Mutual Exclusion(상호 배제)**: 자원이 하나씩만 점유 가능
2. **Hold and Wait(점유 후 대기)**: 자원을 보유한 채 추가 자원 요청
3. **No Preemption(비선점)**: 자원을 강제로 빼앗을 수 없음
4. **Circular Wait(순환 대기)**: 서로가 상대 자원을 요구하며 순환 구조 형성

### OS-053

그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?

- Deadlock은 **4조건이 동시에 충족될 때만 발생**한다.
- 하나라도 깨지면 순환 대기 또는 자원 점유 정체가 발생할 수 없기 때문에 교착상태가 생기지 않는다.
  예) “No Preemption”을 제거 → 강제로 자원 회수 가능 → Deadlock 불가

### OS-054

어떤 방식으로 예방할 수 있을까요?

- Deadlock 조건 중 최소 하나를 무너뜨리기
- **자원 계층(Resource Ordering)**: 순서 규칙 enforce
- **은행원 알고리즘(Banker’s Algorithm)**: 안전 상태만 허용
- **타임아웃(time-out)**: 일정 시간 후 자원 회수
- **자원 선점 가능하게 구현**
- **정해진 순서대로 Lock 획득**

### OS-055

왜 현대 OS는 Deadlock을 처리하지 않을까요?

- Deadlock 탐지·복구는 비용이 매우 큼
- 복잡한 시스템에서는 탐지가 어려움
- 실제로 Deadlock 확률이 낮음
- 개발자가 애플리케이션 코드 수준에서 해결 가능
- OS는 예방책(futex, 두 단계 락, 재시도 등)만 제공
  → 따라서 일반 OS는 Deadlock을 **탐지·회복하지 않고 “회피/예방” 중심으로 설계**

### OS-056

Wait Free와 Lock Free를 비교해 주세요.

- Wait Free: 모든 스레드가 유한한 시간 안에 반드시 종료
  - 가장 강한 강도
  - 기아 상태 없음
  - 실시간 시스템에 유리
- Lock Free: 일부 스레드는 늦어질 수 있으나 시스템 전체 진전 보장
  - 중간 강도
  - 기아 상태 가능
  - 일반 멀티스레드 환경

---

## 📌 컴파일

### OS-057

프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.

일반적인 컴파일 언어(C/C++) 기준:

1. **전처리(Preprocessing)**
   - #include, #define 처리
2. **컴파일(Compilation)**
   - 고급 언어 → 어셈블리 코드 변환
3. **어셈블(Assembling)**
   - 어셈블리 → 목적 코드(Object file)
4. **링킹(Linking)**
   - 여러 오브젝트 파일 + 라이브러리를 묶어 실행 파일 생성
5. **로딩(Loading)**
   - 운영체제가 메모리에 적재 후 실행

### OS-058

링커와, 로더의 차이에 대해 설명해 주세요.

- 링커: 컴파일 시 여러 오브젝트 파일을 묶어 실행 파일 생성
  - 심볼 해결, 주소 재배치
  - 실행 파일(exe 등) 출력
- 로더: 실행 시 실행 파일을 메모리로 적재
  - 메모리 배치, 페이지 테이블 구성
  - 실행 중인 프로세스 출력

### OS-059

컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.

- 컴파일 언어
  - 실행 전 전체 코드를 **기계어로 변환**
  - 빠른 실행 속도
  - 예: C/C++, Rust, Go
- 인터프리터 언어
  - 코드를 **한 줄씩 읽으며 실행**
  - 개발 속도 빠르지만 실행 속도는 느림
  - 예: Python, Ruby, JavaScript

### OS-060

JIT에 대해 설명해 주세요.

- JIT(Just-In-Time Compilation)는 **실행 중 특정 시점에 기계어로 컴파일하는 방식**
- 인터프리터 유연성 + 컴파일 언어의 속도 결합
- Hotspot 최적화 가능 (자주 실행되는 코드 성능 개선)
- JVM, V8 엔진 등이 사용

### OS-061

본인이 사용하는 언어는, 어떤식으로 컴파일 및 실행되는지 설명해 주세요.

**Java 기준 예시**

1. .java → **Java Compiler(javac)** → .class (Bytecode)
2. JVM이 바이트코드를 읽음
3. 자주 실행되는 부분은 **JIT 컴파일러**가 기계어로 변환
4. 실행

### OS-062

Python 같은 언어는 CPython, Jython, PyPy등의 다양한 구현체가 있습니다. 각각은 어떤 차이가 있을까요? 또한, 실행되는 과정 또한 다를까요?

- CPython: 공식 구현체, C로 작성, 인터프리터 방식 + 바이트코드 실행
- PyPy: JIT 컴파일러, CPython보다 빠를 수 있음
- Jython: Python 코드를 JVM 위에서 실행
- IronPython: .NET CLR 기반 Python 실행

### OS-063

우리는 흔히 fork(), exec() 시스템 콜을 사용하여 프로세스를 적재할 수 있다고 배웠습니다. 로더의 역할은 이 시스템 콜과 상관있는 걸까요? 아니면 다른 방식으로 프로세스를 적재할 수 있는 건가요?

- fork() → 부모의 주소공간을 복사하며 **자식 프로세스 생성**
- exec() → 프로세스의 주소공간을 **새로운 프로그램으로 교체**
- 이때 로더가 실행되어
  - 실행 파일을 메모리에 적재
  - 필요한 페이지 테이블 구성
  - 초기화 후 실행

즉, exec() 호출 시 **로더가 프로그램 적재를 담당한다.**
fork()는 프로세스를 복사하는 것이고, exec()은 로더에게 새 프로그램 적재를 시키는 것.
