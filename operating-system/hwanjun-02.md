## 📌 IPC 및 스레드 안전성

### OS-064

IPC가 무엇이고, 어떤 종류가 있는지 설명해 주세요.

- IPC(Inter-Process Communication)는 프로세스 간 통신을 의미하며, 서로 다른 프로세스가 데이터를 교환하기 위한 메커니즘
- 대표적인 방식으로는 파이프, 메시지 큐, 공유 메모리, 소켓, 시그널, 세마포어
- 파이프와 메시지 큐는 메시지 기반이고, 공유 메모리는 속도가 빠르지만 동기화가 필요하며, 소켓은 네트워크 기반 통신도 지원한다는 점이 특징

### OS-065

Shared Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해 주세요.

- Shared Memory는 여러 프로세스가 같은 물리 메모리를 공유하면서 가장 빠르게 IPC를 수행할 수 있는 방식
- 동시에 접근할 수 있기 때문에 Race Condition 위험이 크고, 세마포어나 락 같은 명시적 동기화가 필수
  -> 빠른 대신 동기화 비용 관리가 핵심

### OS-066

메시지 큐는 단방향이라고 할 수 있나요?

- 메시지 큐는 기본적으로 단방향 큐 구조
- 양방향 통신이 필요하다면, 큐를 두 개 생성해 각 방향을 분리하는 방식으로 구현

### OS-067

Thread Safe 하다는 것은 어떤 의미인가요?

- 여러 스레드가 동시에 같은 자원에 접근해도 데이터가 망가지지 않고 일관성이 유지되는 상태를 의미

### OS-068

Thread Safe 를 보장하기 위해 어떤 방법을 사용할 수 있나요?

- 락이나 synchronized 같은 상호 배제
  - 공유 자원에 접근할 때 임계 구역을 설정하고, 한 스레드가 해당 구역을 점유하면 다른 스레드는 대기(block) 시킴
  - Java의 synchronized
  - ReentrantLock
  - mutex/semaphore
- CAS(Compare And Swap) 기반의 원자적 연산
  - 락 없이도 값을 안전하게 변경하는 원자적 연산으로, CPU 하드웨어 명령어(compare-and-swap)를 통해 현재 값이 예상 값과 같을 때만 갱신하도록 보장
- immutable 객체
  - 값이 변하지 않기 때문에 여러 스레드가 동시에 읽거나 가져가도 충돌이 발생하지 않음
- ThreadLocal 저장소
  - 스레드마다 자기만의 독립된 값을 가지게 하는 저장소
  - 즉, 같은 변수명을 쓰더라도 스레드별로 별도의 공간을 가지므로 Race Condition이 원천적으로 제거
- Lock-free 자료구조 사용
  - 원자적 연산을 활용해 락 없이도 여러 스레드가 동시에 접근 가능한 자료구조
  - ConcurrentLinkedQueue, ConcurrentHashMap 등

### OS-069

Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.

- 두 개의 스레드 간 상호 배제를 소프트웨어적으로 보장하는 고전 알고리즘
- Busy-waiting을 사용해 CPU 낭비가 발생하고, 2개 스레드만 지원하며, 최신 CPU의 메모리 모델에서는 메모리 재정렬로 인해 완전한 보장이 어렵다는 한계가 존재한다

### OS-070

Race Condition 이 무엇인가요?

- 여러 스레드가 동시에 같은 자원에 접근할 때 접근 순서에 따라 결과가 달라지는 문제
- 공유 데이터의 수정 과정이 겹칠 때 특히 발생

### OS-071

Thread Safe를 구현하기 위해 반드시 락을 사용해야 할까요? 그렇지 않다면, 어떤 다른 방법이 있을까요?

- 락이 필수는 아니다.
- CAS 기반 원자적 연산(Atomic), immutable 객체, 메시지 큐 기반 Actor 모델, ThreadLocal 같은 방식도 락 없이 thread-safe를 만들 수 있다
- 락은 직관적이지만 성능 비용이 있어 상황에 맞게 대체 기법을 사용

### OS-072

Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.

- Thread Pool: 스레드를 미리 만들어 두고 작업을 큐에 넣어 재사용하는 구조(SpringBoot)
- Monitor: 락과 조건변수를 묶어 객체 단위로 상호 배제 + 조건 동기화를 제공하는 개념
- Fork-Join: 작업을 쪼개서 병렬로 처리한 뒤 합치는 병렬 프레임워크

### OS-073

Thread Pool을 사용한다고 가정하면, 어떤 기준으로 스레드의 수를 결정할 것인가요?

- CPU-bound 작업은 CPU 코어 수 정도, IO-bound 작업은 대기 시간이 많기 때문에 코어 수 × 2~수십 배까지 늘리는 것이 일반적
- 핵심은 ‘CPU 계산 시간 대비 I/O 대기 비율’을 기반으로 설정하는 것

### OS-074

어떤 데이터를 정렬 하려고 합니다. 어떤 방식의 전략을 사용하는 것이 가장 안전하면서도 좋은 성능을 낼 수 있을까요?

- 공유 데이터를 직접 수정하기보다는 별도 버퍼에서 정렬 후 교체하는 방식이 가장 안전
- 병렬 정렬이 가능하면 Merge Sort 기반 Parallel Sort를 사용해 스레드 안전성과 성능을 모두 확보

---

## 📌 캐시

### OS-075

캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.

- 캐시는 CPU와 메모리 사이의 고속 버퍼로, 속도 차이를 줄이기 위해 L1, L2, L3 같은 계층 구조로 구성
- CPU에 가까울수록 빠르고 용량이 작고, 이를 통해 메모리 지연을 최소화

### OS-076

캐시 메모리는 어디에 위치해 있나요?

- 주로 CPU 칩 내부에 L1, L2가 있고, L3는 같은 패키지의 공유 캐시로 존재하는 경우가 많다

### OS-077

L1, L2 캐시에 대해 설명해 주세요.

- L1은 가장 작고 빠르며, 명령어/데이터 캐시로 나뉘는 경우가 많다
- L2는 L1보다 느리지만 용량이 더 크고, CPU 성능 균형을 맞추는 역할

### OS-078

캐시에 올라오는 데이터는 어떻게 관리되나요?

- 교체 알고리즘(LRU, FIFO), 쓰기 정책(Write-through, Write-back)으로 관리
- 캐시는 성능을 위해 CPU가 자주 쓰는 데이터를 예측하여 보관

### OS-079

캐시간의 동기화는 어떻게 이루어지나요?

- 멀티코어 환경에서는 MESI 같은 캐시 일관성 프로토콜로 각 캐시의 데이터를 동기화해 일관성을 보장

### OS-080

캐시 메모리의 Mapping 방식에 대해 설명해 주세요.

- Direct-mapped
  - 메모리의 특정 블록이 캐시의 단 한 칸에만 저장될 수 있는 방식
  - 주소를 ‘태그(Tag) / 인덱스(Index) / 오프셋(Offset)’으로 나누고 인덱스 값에 의해 캐시 라인의 위치가 고정
- Fully-associative
  - 메모리 블록이 캐시 내 모든 라인 어디든 저장될 수 있는 방식
  - 인덱스가 없고, 전체 캐시를 대상으로 태그 비교를 수행
- Set-associative
  - Direct-mapped와 Fully-associative의 절충형 구조
  - 캐시를 여러 개의 Set으로 나누고, 각 Set 안에서만 Fully-associative처럼 저장
- Set-associative는 충돌과 성능의 균형을 가장 잘 맞혀 실제로 가장 널리 쓰임

### OS-081

캐시의 지역성에 대해 설명해 주세요.

- 시간 지역성: 최근 사용한 데이터가 다시 사용될 가능성이 높다
- 공간 지역성: 인접한 데이터가 함께 사용될 가능성이 높다

### OS-082

캐시의 지역성을 기반으로, 이차원 배열을 가로/세로로 탐색했을 때의 성능 차이에 대해 설명해 주세요.

- 메모리가 행 우선 저장이라 가로 탐색은 연속 접근이 되어 캐시 히트율이 높고, 세로 탐색은 캐시 미스가 많아 성능이 떨어진다

### OS-083

캐시의 공간 지역성은 어떻게 구현될 수 있을까요? (힌트: 캐시는 어떤 단위로 저장되고 관리될까요?)

- 캐시는 캐시 라인(일반적으로 수십 바이트) 단위로 데이터를 로드하기 때문에 공간 지역성이 자연스럽게 구현

---

## 📌 메모리 할당

### OS-084

연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)

- First-fit: 처음 맞는 공간을 사용해 빠름
- Best-fit은 가장 작은 적합 공간을 선택해 외부 단편화를 줄인다
- Worst-fit은 가장 큰 공간을 사용해 큰 블록을 남겨두려는 전략

### OS-085

worst-fit 은 언제 사용할 수 있을까요?

- 큰 프로세스가 자주 들어오는 환경에서 큰 공간을 유지하고 싶을 때 사용

### OS-086

성능이 가장 좋은 알고리즘은 무엇일까요?

- 일반적으로 First-fit이 가장 빠르고 현실적인 성능을 제공

### OS-087

Thrashing 이란 무엇인가요?

- 페이지 교체가 너무 빈번해 CPU가 실제 작업이 아니라 스왑만 하는 비정상적 상태

### OS-088

Thrashing 발생 시, 어떻게 완화할 수 있을까요?

- 작업 집합 조절, 메모리 증설, 다중 프로그래밍 정도 감소, 더 효율적인 페이지 교체 알고리즘 도입 등

---

## 📌 가상 메모리

### OS-089

가상 메모리란 무엇인가요?

- 물리 메모리보다 더 큰 주소 공간을 프로그램에 제공하는 추상화 기술
- 필요한 페이지만 로딩하는 방식으로 효율 높임

### OS-090

가상 메모리가 가능한 이유가 무엇일까요?

- 프로세스 전체가 항상 메모리에 있을 필요가 없고, 페이지 단위로 필요한 부분만 불러오는 Demand Paging 때문

### OS-091

Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.

- Page Fault가 나면 OS가 디스크에서 해당 페이지를 읽어 프레임에 올리고, 페이지 테이블을 갱신한 뒤 명령을 재시작

### OS-092

페이지 크기에 대한 Trade-Off를 설명해 주세요.

- 페이지가 크면 -> page fault는 줄지만 내부 단편화가 증가
- 페이지가 작으면 -> fault는 늘지만 메모리 사용 효율은 좋아짐

### OS-093

페이지 크기가 커지면, 페이지 폴트가 더 많이 발생한다고 할 수 있나요?

- 일반적으로 페이지가 크면 더 많은 데이터를 담아 fault는 줄어든다

### OS-094

세그멘테이션 방식을 사용하고 있다면, 가상 메모리를 사용할 수 없을까요?

- 세그멘테이션만으로도 가상 주소를 만들 수 있고, 실제로는 페이징과 혼합해 사용해 효율을 높인다

### OS-095

세그멘테이션과 페이징의 차이점은 무엇인가요?

- 세그멘테이션은 의미 기반 영역이고 크기가 가변
- 페이징은 고정 크기 블록 기반으로 단편화 문제를 해결

### OS-096

페이지와 프레임의 차이에 대해 설명해 주세요.

- 페이지는 프로세스의 논리적 블록이고, 프레임은 물리 메모리의 고정 크기 블록

### OS-097

내부 단편화와, 외부 단편화에 대해 설명해 주세요.

- 내부 단편화는 할당된 영역 내부의 낭비
- 외부 단편화는 작은 빈 공간이 흩어져 연속 공간을 못 쓰는 문제

### OS-098

페이지에서 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.

- 페이지 번호를 페이지 테이블에서 찾아 프레임 번호로 변환하고, offset을 더해 최종 물리 주소를 생성

### OS-099

어떤 주소공간이 있을 때, 이 공간이 수정 가능한지 확인할 수 있는 방법이 있나요?

- 페이지 테이블의 R/W, Execute 권한 비트를 보고 판단

### OS-100

32비트에서, 페이지의 크기가 1kb 이라면 페이지 테이블의 최대 크기는 몇 개일까요?

- 4GB / 1KB = 약 419만 페이지

### OS-101

32비트 운영체제는 램을 최대 4G 까지 사용할 수 있습니다. 이 이유를 페이징과 연관 지어서 설명해 주세요.

- 32비트는 2³², 즉 4GB까지만 주소 표현이 가능하기 때문

### OS-102

C/C++ 개발을 하게 되면 Segmentation Fault 라는 에러를 접할 수 있을텐데, 이 에러는 세그멘테이션/페이징과 어떤 관계가 있을까요?

- 잘못된 주소 접근 시 페이지 테이블/세그먼트 테이블에서 권한 위반이 발생하며 OS가 Fault로 프로그램을 종료

---

## 📌 TLB

### OS-103

TLB는 무엇인가요?

- TLB는 페이지 테이블의 일부를 저장하는 주소 변환 캐시로, 가상→물리 주소 변환을 빠르게 수행

### OS-104

TLB를 쓰면 왜 빨라지나요?

- 메모리 접근마다 페이지 테이블을 읽지 않고, TLB에서 바로 프레임 번호를 찾기 때문

### OS-105

MMU가 무엇인가요?

- MMU는 가상 주소를 물리 주소로 변환하는 하드웨어

### OS-106

TLB와 MMU는 어디에 위치해 있나요?

- 둘 다 CPU 내부 또는 매우 근접한 위치

### OS-107

코어가 여러개라면, TLB는 어떻게 동기화 할 수 있을까요?

- TLB Shootdown 방식을 사용해, 페이지 변경 시 각 코어의 TLB 엔트리를 무효

### OS-108

TLB 관점에서, Context Switching 발생 시 어떤 변화가 발생하는지 설명해 주세요.

- 다른 프로세스로 전환되므로 이전 프로세스의 TLB는 무효화되고 새로운 주소 공간으로 교체

### OS-109

동기화를 구현하기 위한 하드웨어적인 해결 방법에 대해 설명해 주세요.

- CAS, Test-and-set, Fetch-and-add 같은 원자적 명령어를 제공해 락 없이 동기화를 지원

### OS-110

volatile 키워드는 어떤 의미가 있나요?

- 변수를 CPU 캐시가 아닌 메모리에서 읽도록 강제해, 최신 값을 보장

### OS-111

싱글코어가 아니라 멀티코어라면, 어떻게 동기화가 이뤄질까요?

- MESI 같은 캐시 일관성 프로토콜과, 원자적 명령어를 조합해 동기화 구현

---

## 📌 페이지 교체 알고리즘

### OS-112

페이지 교체 알고리즘에 대해 설명해 주세요.

- 새 페이지가 필요할 때 어떤 페이지를 내쫓을지 결정하는 알고리즘

### OS-113

LRU 알고리즘은 어떤 특성을 이용한 알고리즘이라고 할 수 있을까요?

- 최근에 사용된 데이터는 다시 사용할 확률이 높다는 시간 지역성 기반 알고리즘

### OS-114

LRU 알고리즘을 구현한다면, 어떻게 구현할 수 있을까요?

- LinkedHashMap 같은 리스트+해시 조합, 또는 reference bit 기반의 Aging 알고리즘으로 구현

### OS-115

LRU 알고리즘의 단점을 설명해 주세요. 이를 해결할 수 있는 대안에 대해서도 설명해 주세요.

- 구현 비용이 높고 캐시 미스 시마다 업데이트 비용이 크다
- 대안으로 **Clock 알고리즘(Second Chance)**을 사용해 성능을 개선

---

## 📌 파일 시스템 및 I/O

### OS-116

File Descriptor와, File System에 에 대해 설명해 주세요.

- FD: 열린 파일을 식별하는 정수 핸들
- File System은 파일을 디스크에 저장·관리하는 계층 구조

### OS-117

I-Node가 무엇인가요?

- 파일의 메타데이터(size, block 위치 등)를 관리하는 구조체로, 파일 내용과는 별도로 저장됨

### OS-118

프로그래밍 언어 상에서 제공하는 파일 관련 함수 (Python - open(), Java - BufferedReader/Writer 등)은, 파일을 어떤 방식으로 읽어들이나요?

- 언어의 파일 API는 내부적으로 커널의 read()를 호출하고, 커널은 블록 캐시를 사용해 효율적으로 데이터를 읽는다

### OS-119

동기와 비동기, 블로킹과 논블로킹의 차이에 대해 설명해 주세요.

- 동기·비동기는 완료 여부를 기다리는지의 차이
- 블로킹·논블로킹은 호출 스레드가 멈추는지의 차이

### OS-120

그렇다면, 동기이면서 논블로킹이고, 비동기이면서 블로킹인 경우는 의미가 있다고 할 수 있나요?

- 이론적으로 가능하지만 실용적이지 않고 의미도 거의 없다

### OS-121

I/O 멀티플렉싱에 대해 설명해 주세요.

- select/poll/epoll로 여러 파일 디스크립터를 한 스레드에서 감시하는 기술

### OS-122

논블로킹 I/O를 수행한다고 하면, 그 결과를 어떻게 수신할 수 있나요?

- 반복 확인(polling), 이벤트 기반(epoll), callback/completion queue 방식으로 처리
