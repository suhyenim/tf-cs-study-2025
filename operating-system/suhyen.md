# Operating System (운영체제)

## 📌 시스템 콜

### OS-001
<details>
<summary>시스템 콜이 무엇인지 설명해 주세요.</summary>
<hr>

시스템 콜(System Call)은 사용자 프로그램이 운영체제의 커널 기능에 접근하기 위해 사용하는 인터페이스입니다.

사용자 프로그램이 파일 시스템 접근, 프로세스 생성, 메모리 할당 등의 작업을 수행할 때, 직접 하드웨어에 접근하는 대신, 시스템 콜을 통해 운영체제에 요청합니다. 이를 통해 운영체제는 안전하고 효율적으로 자원을 관리할 수 있습니다.

</details>

### OS-002
<details>
<summary>우리가 사용하는 시스템 콜의 예시를 들어주세요.</summary>
<hr>

일상적으로 많이 사용하는 시스템 콜의 예로는 파일을 열고 읽고 쓰는 작업을 위한 open, read, write, close 등이 있습니다.

또한, 새로운 프로세스를 생성하는 fork, 새로운 프로그램을 실행하는 exec, 프로세스를 종료하는 exit도 대표적인 시스템 콜입니다.

네트워크 프로그래밍에서 사용하는 socket, bind, listen, accept도 시스템 콜의 예에 해당합니다.

</details>

### OS-003
<details>
<summary>시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.</summary>
<hr>

먼저, 사용자 프로그램이 시스템 콜을 호출하면 CPU는 사용자 모드에서 커널 모드로 전환됩니다. 이때 시스템 콜 번호가 CPU 레지스터에 저장되고, 커널은 이 번호를 참조하여 시스템 콜 테이블에서 해당 시스템 콜을 처리할 함수 포인터를 찾습니다.

이후 커널은 해당 함수(예: sys_fork 등)를 실행하여 작업을 수행하고, 결과를 사용자 모드로 반환합니다.

마지막으로, CPU는 다시 사용자 모드로 전환되어 프로그램이 실행을 이어갑니다.   

</details>

### OS-004
<details>
<summary>시스템 콜의 유형에 대해 설명해 주세요.</summary>
<hr>

프로세스 제어 시스템 콜은 fork, exec, exit처럼 프로세스를 생성, 실행, 종료하는 작업을 담당합니다.

파일 조작 시스템 콜은 open, read, write, close처럼 파일을 열고 읽고 쓰는 작업을 수행합니다.

장치 관리 시스템 콜은 ioctl처럼 하드웨어 장치의 제어를 담당합니다.

정보 유지 시스템 콜은 getpid, alarm처럼 시스템 정보 조회 및 설정을 위한 작업을 수행하며,

통신 시스템 콜은 pipe, socket처럼 프로세스 간의 통신을 처리합니다.   

</details>

### OS-005
<details>
<summary>운영체제의 Dual Mode에 대해 설명해 주세요.</summary>
<hr>

운영체제의 Dual Mode는 사용자 모드(User Mode)와 커널 모드(Kernel Mode)로 나뉩니다.

사용자 모드는 애플리케이션 프로그램이 실행되는 제한된 권한 모드로, 시스템 자원에 직접 접근할 수 없습니다.

커널 모드는 운영체제가 실행되는 모드로, 모든 하드웨어 자원에 대한 완전한 접근 권한을 가집니다.

이러한 두 모드를 구분함으로써 운영체제는 시스템의 안전성과 안정성을 유지할 수 있습니다.

예를 들어, 사용자 프로그램이 하드웨어 자원에 직접 접근하지 못하도록 하고, 시스템 콜을 통해서만 접근할 수 있게 제한합니다.

</details>

### OS-006
<details>
<summary>왜 유저모드와 커널모드를 구분해야 하나요?</summary>
<hr>

유저모드와 커널모드를 구분하는 주된 이유는 시스템의 보안과 안정성을 보장하기 위해서입니다.

유저모드에서 실행되는 프로그램이 시스템의 중요한 자원에 직접 접근하지 못하도록 함으로써 악성 코드나 버그로 인한 시스템 손상을 방지할 수 있습니다.

또한, 커널 모드에서만 중요한 시스템 자원(예: 메모리, CPU, 디스크)에 접근할 수 있도록 하여 시스템의 안정성을 유지할 수 있습니다.    

</details>

### OS-007
<details>
<summary>서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?</summary>
<hr>

시스템 콜 번호를 통해 구분됩니다. 각 시스템 콜은 고유한 번호를 가지고 있으며, 이 번호는 시스템 콜이 호출될 때 CPU 레지스터에 저장됩니다.

커널은 이 번호를 참조하여 시스템 콜 테이블에서 해당 번호에 해당하는 함수 포인터를 찾아 호출합니다.   

</details>

## 📌 인터럽트

### OS-008
<details>
<summary>인터럽트가 무엇인지 설명해 주세요.</summary>
<hr>

CPU가 프로그램을 실행하고 있을 때, 하드웨어장치 혹은 예외상황의 처리가 필요할 때 CPU에게 알려 이를 처리할 수 있도록 하는 일종의 신호입니다.

</details>

### OS-009
<details>
<summary>인터럽트는 어떻게 처리하나요?</summary>
<hr>

인터럽트는 인터럽트 요청(Interrupt Request, IRQ) 단위로 처리되며, 각각의 인터럽트는 고유한 IRQ 번호를 가지고 있어 CPU가 어떤 장치나 이벤트에서 인터럽트를 발생시켰는지 식별할 수 있습니다.

인터럽트 신호가 발생했을 때 cpu는 인터럽트 플래그를 통해 현재 인터럽트를 받아들일 수 있는지 확인합니다.

인터럽트를 받아들일 수 있다면, cpu는 현재 작업의 상태를 스택에 백업하고(문맥 교환), 인터럽트 벡터를 참조하여 인터럽트 서비스 루틴을 실행합니다.

인터럽트 서비스 루틴이 끝나면 cpu는 백업해 둔 작업을 복구하여 실행을 재개합니다.

> 인터럽트 요청 신호
> - 인터럽트를 요청하는 신호
> - 인터럽트 요청을 수용하기 위해서는 플래그 레지스터의 인터럽트 플래그가 활성화되어 있어야 한다.
>
> 인터럽트 플래그
> - 하드웨어 인터럽트를 받아들일지 결정하는 플래그
> - 인터럽트 플래그가 비활성화되어 있다면 인터럽트 요청이 무시된다.
> - 그러나 정전, 하드웨어 고장으로 인한 인터럽트 등 막을 수 없는 인터럽트는 우선순위가 높아 플래그에 관계없이 인터럽트가 받아들여진다.
>
> 인터럽트 서비스 루틴 (ISR)
> - 인터럽트를 처리하기 위한 프로그램으로 인터럽트를 처리하는 방법이 담겨 있다.
> - 인터럽트 핸들러라고도 불린다.
> - cpu가 인터럽트를 처리한다는 것은 인터럽트 서비스 루틴을 실행하고 이전작업으로 다시 돌아온다는 것을 의미한다.
>  
> 인터럽트 벡터
> - 인터럽트 서비스 루틴을 식별하기 위한 정보
> - 인터럽트 벡터로 서비스 루틴의 시작 주소를 알 수 있다.

</details>

### OS-010
<details>
<summary>Polling 방식에 대해 설명해 주세요.</summary>
<hr>

CPU가 주기적으로 각 장치나 프로그램의 상태를 확인하여 작업이 필요한지 확인하는 방식입니다.

인터럽트 없이 시스템의 상태를 지속적으로 확인할 수 있으나, CPU의 리소스를 많이 소모하게 됩니다.

</details>

### OS-011
<details>
<summary>HW / SW 인터럽트에 대해 설명해 주세요.</summary>
<hr>

하드웨어 장치(예: 키보드, 마우스, 네트워크 카드 등)에서 발생하는 비동기 방식 인터럽트입니다. 예를 들어, 키보드에서 키를 누를 때 하드웨어 인터럽트가 발생하여 CPU가 이를 처리합니다.

소프트웨어가 의도적으로 발생시키는 동기화 방식 인터럽트입니다. 주로 프로그램이 특정 작업을 수행하기 위해 OS에 요청을 보낼 때 사용됩니다.

</details>

### OS-012
<details>
<summary>동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?</summary>
<hr>

동시에 인터럽트가 발생하면 cpu는 인터럽트 우선순위를 기준으로 인터럽트를 처리합니다. 이때, 선점형 방식으로 동작하게되며 우선순위 설정은 필요한 기준에 따라 우선순위가 결정됩니다.

일반적 기준: 전원 이상(Power fail) > 기계 착오(Machine Check) > 외부 신호(External) > 입출력(I/O) > 명령어 잘못 > 프로그램 검사(Program Check) > SVC(SuperVisor Call)

</details>

## 📌 프로세스

### OS-013
<details>
<summary>프로세스가 무엇인가요?</summary>
<hr>

프로세스는 실행중인 하나의 프로그램을 의미합니다. 즉, 메모리에 올라와 실시간으로 작동하고 있는 프로그램을 의미합니다.

</details>

### OS-014
<details>
<summary>프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.</summary>
<hr>

프로세스는 실행 중인 하나의 프로그램을 의미하며 실행의 단위라고 할 수 있습니다. 

반면 스레드는 프로세스 내에서 실행되는 흐름의 단위를 의미합니다. 

그래서 프로세스는 독립적인 메모리 영역을 갖게 되지만, 스레드는 스택 영역에서만 독립적이며, 그 외의 영역들은 다른 스레드와 공유합니다.

</details>

### OS-015
<details>
<summary>PCB가 무엇인가요?</summary>
<hr>

PCB는 Process Control Block의 약자로, "프로세스 제어블록" 이라고 말하며 운영체제가 프로세스 상태관리와 문맥 교환을 위한 정보를 저장하는 구조체 입니다.

저장되는 정보로는 고유 아이디인 PID(프로세스 ID), 프로세스가 다음으로 실행해야 하는 명령어의 주소 값인 PC, CPU의 레지스터에 저장되는 정보 등이 있습니다.

프로세스 생성시 커널 영역에 생성되며, 종료시 폐기됩니다. (중요한 정보를 담고 있으므로 일반 사용자로부터 접근을 막아야함)

</details>

### OS-016
<details>
<summary>그렇다면, 스레드는 PCB를 갖고 있을까요?</summary>
<hr>

PCB는 갖고있지 않지만, 비슷한 개념인 TCB라는 개념이 존재합니다. TCB는 Thread별로 존재하는 자료구조이며, PC와 Register Set(CPU 정보), 그리고 PCB를 가리키는 포인터를 가지고 있습니다.

</details>

### OS-017
<details>
<summary>리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?</summary>
<hr>

프로세스 생성을 위해서는 fork() 함수를 호출하여 생성할 수 있습니다.
fork() 함수에는 함수를 호출한 프로세스를 복사하는 기능이 존재합니다.
이때 기존 프로세스를 부모 프로세스, 복사된 프로세스를 자식 프로세스라고 불리우는데, fork() 함수를 호출하면 부모 프로세스는 자식 프로세스의 PID 값을, 자식 프로세스는 0을 반환합니다.

스레드는 pthread_create() 함수를 호출하여 같은 프로세스 안에서 새로운 스레드를 하나 더 시작하고, 이 스레드는 start_routine으로 넘긴 함수부터 실행을 시작합니다.

</details>

### OS-018
<details>
<summary>자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?</summary>
<hr>

1. 자식 프로세스가 종료되었지만 부모 프로세스가 이를 처리하지 않은 경우: 좀비 프로세스   
2. 부모 프로세스가 먼저 종료된 경우: 고아 프로세스

좀비 프로세스
- 좀비 프로세스(Zombie Process)란 자식 프로세스가 종료되었지만, 부모 프로세스가 자식의 종료 상태를 확인하지 않은 상태를 말합니다. 이때 자식 프로세스는 종료되었지만 프로세스 테이블에 여전히 남아 있는 상태로, 자원의 일부가 해제되지 않고 남아 있습니다.
- 해결 방법: 부모 프로세스가 자식 프로세스의 종료를 인지하고 `wait()` 또는 `waitpid()` 함수를 호출하여 자식 프로세스의 종료 상태를 수거하면, 좀비 프로세스가 제거됩니다. `wait()` 함수는 부모 프로세스가 자식 프로세스의 종료 상태를 읽어 들여, 자식 프로세스의 프로세스 테이블 엔트리를 해제하는 역할을 합니다. 만약 부모 프로세스가 `wait()`를 호출하지 않으면, 좀비 프로세스가 계속 남아 있게 되어 시스템 자원을 낭비할 수 있습니다.

고아 프로세스
- 고아 프로세스(Orphan Process)란 부모 프로세스가 먼저 종료되고, 자식 프로세스가 아직 종료되지 않은 상태를 말합니다. 자식 프로세스는 여전히 실행 중이지만, 이제 부모 프로세스가 없기 때문에 고아 상태가 됩니다.
- 해결 방법: 리눅스에서는 고아 프로세스를 처리하기 위해, 자식 프로세스의 부모 프로세스를 `init` 프로세스(PID 1)로 재할당합니다. `init` 프로세스는 모든 고아 프로세스를 자동으로 인수하여, 자식 프로세스가 종료될 때 그 자원을 수거합니다. 이로 인해 고아 프로세스가 시스템에 영향을 미치는 일이 없게 됩니다. `init` 프로세스는 시스템에서 가장 중요한 프로세스 중 하나로, 시스템 부팅 시 가장 먼저 실행되며, 항상 실행 상태를 유지합니다.

</details>

### OS-019
<details>
<summary>리눅스에서, 데몬프로세스에 대해 설명해 주세요.</summary>
<hr>

프로세스는 크게 2가지로 포그라운드 프로세스와 백그라운드 프로세스가 존재합니다. 포그라운드 프로세스는 사용자가 볼 수 있는 공간에서 실행되는 프로세스이며, 백그라운드 프로세스는 사용자가 볼 수 없는 공간에서 실행되는 프로세스 입니다. 백그라운드 프로세스에서 사용자와 상호작용이 가능한 프로세스가 있는 반면에, 사용자와 상호작용하지 않아도 작업을 수행하고 있는 독립적인 프로세스를 데몬 프로세스라고 칭합니다.

</details>

### OS-020
<details>
<summary>리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.</summary>
<hr>

pstree라는 명령어로 확인 가능한데, 과거에는 init 프로세스가 최초 프로세스였으며, 시스템이 부팅될 때 가장 먼저 실행되는 프로세스로 모든 다른 프로세스의 부모 역할을 합니다.

현재는 systemd 라는 프로세스가 최초의 프로세스 입니다. "systemd"는 부팅 과정에서 다양한 서비스와 프로세스를 관리하여 전통적인 init 프로세스의 역할을 확장한 것입니다.

</details>

## 📌 프로세스 주소공간

### OS-021
<details>
<summary>프로세스 주소공간에 대해 설명해 주세요.</summary>
<hr>

프로세스의 메모리 영역은 크게 스택(Stack), 힙(Heap), 데이터(Data), 코드(Code) 영역으로 나뉩니다.

- **스택(Stack)**: 함수 호출 시 생성되는 지역 변수와 매개변수가 저장되는 임시 저장 공간입니다. 스택은 LIFO(Last In, First Out) 구조로 동작하며, 컴파일 시 크기가 결정됩니다.

- **힙(Heap)**: 프로그래머가 동적으로 메모리를 할당할 수 있는 공간으로, 런타임 시에 크기가 동적으로 조정됩니다. malloc(), free() 등의 함수로 힙 영역을 관리할 수 있습니다.

- **데이터(Data) 영역**: 전역 변수, static 변수 등이 저장되는 공간입니다. 데이터 영역은 초기화 여부에 따라 BSS(BSS Segment)와 데이터(Data Segment) 영역으로 나뉩니다. 초기화되지 않은 변수는 BSS 영역에, 초기화된 변수는 데이터 영역에 저장됩니다.

- **코드(Code) 영역**: 실행할 프로그램의 기계어 코드가 저장되는 공간입니다. 이 영역은 읽기 전용으로 설정되어 있어 프로그램이 실행되는 동안 수정할 수 없습니다.

</details>

### OS-022
<details>
<summary>초기화 하지 않은 변수들은 어디에 저장될까요?</summary>
<hr>

초기화되지 않은 전역 변수와 static 변수는 데이터 영역의 BSS(BSS Segment) 영역에 저장됩니다. BSS 영역은 초기화되지 않은 전역 변수와 static 변수를 저장하는 영역입니다.

이 영역은 프로그램이 실행되기 전에 자동으로 0으로 초기화되기 때문에, 프로그래머가 명시적으로 값을 초기화하지 않아도 안전하게 사용할 수 있습니다.

</details>

### OS-023
<details>
<summary>일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?</summary>
<hr>

Stack과 Heap 영역의 초기 크기는 일반적으로 매우 크지 않습니다. 스택은 컴파일 시, 힙은 런타임 시에 기본 크기가 결정됩니다. 하지만 두 영역 사이에는 사용 가능한 메모리 공간이 존재하여 동적으로 크기를 확장할 수 있습니다. 예를 들어, 스택의 크기는 주어진 메모리 범위 내에서 증가할 수 있으며, 힙도 malloc()을 통해 동적으로 크기가 확장될 수 있습니다.

</details>

### OS-024
<details>
<summary>Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?</summary>
<hr>

일반적으로 스택의 접근 속도가 더 빠릅니다. 스택은 단순히 포인터의 위치를 조정하는 방식으로 메모리를 할당/해제하는 반면, 힙은 요청된 크기와 메모리 상태를 고려하여 할당하기 때문에 더 많은 CPU 연산이 필요합니다.

</details>

### OS-025
<details>
<summary>다음과 같이 공간을 분할하는 이유가 있을까요?</summary>
<hr>

메모리 영역을 분할하는 주요 이유는 효율적인 메모리 관리와 데이터 공유입니다. 예를 들어, 코드 영역은 읽기 전용으로 설정하여 여러 프로세스가 동일한 코드 영역을 공유할 수 있도록 합니다. 스택과 데이터 영역을 분리하는 이유는 각각의 특성에 맞는 메모리 관리를 통해 성능을 최적화하기 위해서입니다.

</details>

### OS-026
<details>
<summary>스레드의 주소공간은 어떻게 구성되어 있을까요?</summary>
<hr>

스레드는 프로세스 내에서 생성되므로, 프로세스의 주소 공간을 공유합니다.

- **코드(Code) 영역**: 프로세스의 코드 영역을 공유합니다. 모든 스레드는 같은 코드 영역을 실행할 수 있습니다.

- **데이터(Data) 영역**: 전역 변수와 static 변수를 포함한 데이터 영역은 모든 스레드가 공유합니다. 또한 스레드별로 독립적인 스레드 로컬 스토리지(TLS)를 가질 수 있습니다.

- **힙(Heap) 영역**: 모든 스레드가 프로세스의 힙 영역을 공유하며 동적으로 메모리를 할당받을 수 있습니다.

- **스택(Stack) 영역**: 각 스레드는 독립적인 스택을 가지고 있으며, 함수 호출 시 사용됩니다.

</details>

### OS-027
<details>
<summary>"스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.</summary>
<hr>

네, 스택과 힙 영역은 각각의 자료구조와 동작 방식이 연관이 있습니다.

- **스택(Stack)**: 메모리의 높은 주소에서 낮은 주소로 할당되며, 함수 호출 시 메모리를 할당하고, 함수가 종료되면 메모리를 해제합니다. 이는 후입선출(LIFO) 구조와 유사합니다.

- **힙(Heap)**: 메모리의 낮은 주소에서 높은 주소로 할당되며, 프로그래머가 직접 메모리를 할당하고 해제합니다. 힙은 선입선출(FIFO) 구조와는 다르지만, 메모리 할당 방식이 동적이라는 점에서 힙 자료구조와 연관이 있습니다.

</details>

### OS-028
<details>
<summary>IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요?</summary>
<hr>

IPC(Inter-Process Communication) 기법 중 Shared Memory는 일반적으로 프로세스의 데이터 영역 또는 힙 영역에 위치합니다. Shared Memory를 사용하는 이유는 여러 프로세스가 동일한 메모리 영역을 공유함으로써 빠르고 효율적인 데이터 교환을 가능하게 하기 위함입니다. 하지만 이 방식은 동기화 문제가 발생할 수 있으므로 적절한 동기화 기법이 필요합니다.

</details>

### OS-029
<details>
<summary>스택과 힙영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요?</summary>
<hr>

스택 영역의 크기는 컴파일 시, 힙 영역의 크기는 런타임 시에 결정됩니다. 사용자는 일반적으로 직접 이 크기를 수정할 수 없습니다. 하지만, 운영체제의 설정이나 실행 환경에 따라 스택 크기를 조정할 수 있는 옵션이 있을 수 있습니다. 예를 들어, ulimit 명령어나 프로그램 실행 시 설정을 통해 스택 크기를 조정할 수 있습니다.

</details>

## 📌 CPU 스케줄링

### OS-030
<details>
<summary>단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.</summary>
<hr>

장기 스케줄러는 HDD 상의 프로그램을 커널에 등록(or 레디 큐 등록)할 때의 스케줄러입니다.

> 메모리는 한정되어 있기 때문에, 실행할 수 있는 프로세스보다 많은 프로세스가 메모리에 올라오면 대용량 메모리(일반적으로 하드디스크)에 임시로 저장된다. 장기 스케줄러는 하드디스크의 프로세스 중 하나를 선택하여 메모리를 할당하고 Ready Queue로 보내는 역할을 한다.

단기 스케줄러는 레디 큐의 프로세스를 CPU에 할당하여 실행 상태로 만들 때의 스케줄러입니다.

> 일반적인 스케줄러 라고하면 단기 스케줄러를 의미

중기 스케줄러(=Swapper)는 메모리에 적재된 프로세스 수를 관리하는 스케줄러입니다.

> 스와핑(Swapping): 일부 프로세스를 메모리에서 디스크로 보내고(swap-out), 시간이 흘러 메모리에 여유가 생기면 다시 적재(swap-in)한다.

</details>

### OS-031
<details>
<summary>현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?</summary>
<hr>

대부분 장기 스케줄러는 두지 않고있습니다. 이유는 메모리와 CPU 자원이 풍부해져서, 프로세스를 선택적으로 로드할 필요가 줄어들었기 때문입니다. 대신, 대부분의 프로세스를 바로 메모리에 로드하고, 단기 및 중기 스케줄러로 관리하여 효율적으로 프로세스를 실행합니다.

</details>

### OS-032
<details>
<summary>프로세스의 스케쥴링 상태에 대해 설명해 주세요.</summary>
<hr>

생성(New): 프로세스가 처음 생성된 상태.

준비(Ready): 실행을 위해 CPU 할당을 기다리는 상태.

실행(Running): CPU를 할당받아 실행 중인 상태.

대기(Waiting/Blocked): I/O 등 특정 사건을 기다리는 상태.

종료(Terminated): 실행을 마치고 종료된 상태.

중지(Suspended): 메모리에서 스왑 아웃되어 일시적으로 중단된 상태.

![OS-032(1)](./suhyen-img/OS-032(1).png)
![OS-032(2)](./suhyen-img/OS-032(2).png)

</details>

### OS-033
<details>
<summary>preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?</summary>
<hr>

Preemptive(선점형)과 Non-Preemptive(비선점형) 스케줄링 모두에서 모든 프로세스 상태(생성, 준비, 실행, 대기, 종료, 중지)가 존재할 수 있습니다. 차이는 상태 전이 방식에 있으며, 선점형에서는 실행 중인 프로세스가 다른 프로세스에 의해 중단될 수 있지만, 비선점형에서는 실행 중인 프로세스가 스스로 종료되거나 대기 상태로 전환되기 전까지 중단되지 않습니다.

> 비선점형 스케줄링에서 블록 상태가 존재하는 이유는 프로세스가 자발적으로 I/O 작업이나 다른 사건을 기다릴 때 발생한다.

</details>

### OS-034
<details>
<summary>Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?</summary>
<hr>

프로세스는 메모리를 효율적으로 관리하면서 시스템의 성능을 유지하기 위해 일반적으로 중지(Suspended) 상태로 전환되어 디스크에 스왑아웃되거나, 필요한 메모리가 확보될 때까지 대기(Waiting) 상태로 유지됩니다.

</details>

## 📌 컨텍스트 스위칭

### OS-035
<details>
<summary>컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?</summary>
<hr>

컨텍스트 스위칭은 운영체제가 CPU에서 실행 중인 프로세스를 다른 프로세스로 교체할 때 발생하는 과정입니다.

커널(운영체제)이 실행 중인 프로세스의 상태(레지스터, 프로그램 카운터, 스택 포인터 등)를 프로세스 제어 블록(PCB)에 저장합니다. 그 후, 새 프로세스의 PCB에서 상태 정보를 가져와 복구한 후, 해당 프로세스의 실행을 재개합니다.

> 간단 정리: 컨텍스트 스위칭 = 이전 프로세스의 실행 상태를 PCB에 저장 + 새 프로세스의 실행 상태를 PCB에서 꺼내와 CPU에 복구하는 과정

</details>

### OS-036
<details>
<summary>프로세스와 스레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?</summary>
<hr>

프로세스 컨텍스트 스위칭는 독립적인 메모리 공간을 교체해야 하므로 비용이 큽니다. 반면, 스레드 컨텍스트 스위칭는 동일한 메모리 공간을 공유하기 때문에 주로 레지스터와 스택 포인터만 교체하면 되어 비용이 적습니다.

> 프로세스 컨텍스트 스위칭: 페이지 테이블의 교체와 같은 메모리 관리 작업이 필요함 따라서 TLB(Translation Lookaside Buffer) 캐시를 비우거나 업데이트해야 하며 추가비용도 발생 

> 스레드 컨텍스트 스위칭: 데이터 경쟁(race condition)을 방지하기 위한 동기화 메커니즘이 필요할 수도 있음

![OS-036(1)](./suhyen-img/OS-036(1).png)

</details>

### OS-037
<details>
<summary>컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?</summary>
<hr>

컨텍스트 스위칭 시 기존의 프로세스 정보는 커널 스택에 스택 프레임의 형태로 저장됩니다. 이 정보에는 레지스터 값, 프로그램 카운터, 스택 포인터, 플래그 레지스터, 메모리 관리 정보 등이 포함됩니다. 커널 스택에 저장된 정보를 활용해 프로세스의 정확한 상태 복구를 가능하게 하며, 프로세스 제어 블록(PCB)과 밀접하게 연관되어 프로세스의 실행 상태를 관리합니다.

> 프로세스는 user stack과 kernel stack을 가지고 있다. 이건 유저, 커널 모드에서 사용하는 스택이다.

</details>

### OS-038
<details>
<summary>컨텍스트 스위칭은 언제 일어날까요?</summary>
<hr>

1. 타이머 인터럽트(시간 분할 스케줄링): 시간 제한이 도달하면 운영체제가 현재 실행 중인 프로세스를 중단하고, 다른 준비된 프로세스에 CPU를 할당합니다.

> 멀티태스킹 환경에서 모든 프로세스가 공정하게 CPU 시간을 얻을 수 있도록 보장

2. I/O 요청 및 완료: 프로세스가 I/O 작업을 요청하여 대기 상태로 전환되거나, 대기 중이던 I/O 작업이 완료되어 준비 상태로 전환될 때 발생합니다.

> CPU가 I/O 작업을 기다리는 동안 유휴 상태에 있지 않고 다른 작업을 처리할 수 있다.

3. 우선순위 스케줄링: 높은 우선순위를 가진 프로세스가 준비 상태로 전환되면, 현재 실행 중인 프로세스를 중단하고 높은 우선순위 프로세스를 실행하기 위해 컨텍스트 스위칭이 발생합니다.

</details>

## 📌 스케줄링 알고리즘

### OS-039
<details>
<summary>프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?</summary>
<hr>

1. Round Robin (RR): 공정한 시간 분배, 멀티태스킹에서 자주 사용.
2. First-Come, First-Served (FCFS): 간단한 FIFO 방식, 배치 처리에 적합.
3. Shortest Job First (SJF): 평균 대기 시간 최소화, 기아 문제 발생 가능.
4. Priority Scheduling: 중요한 작업 우선 처리, 실시간 시스템에 사용.
5. Multilevel Feedback Queue (MLFQ): 다양한 프로세스 특성 처리, 범용 운영체제에 사용.

</details>

### OS-040
<details>
<summary>RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.</summary>
<hr>

Time Slice가 짧을 때:

장점: 시스템 응답성이 좋아집니다. 각 프로세스가 자주 CPU 시간을 얻기 때문에 사용자가 빠른 응답을 경험할 수 있습니다.   
단점: 빈번한 컨텍스트 스위칭으로 인해 오버헤드가 증가합니다. 컨텍스트 스위칭은 시간이 소모되며, CPU가 실제 작업을 수행하는 시간보다 스위칭에 더 많은 시간을 소모할 수 있습니다.

Time Slice가 길 때:

장점: 컨텍스트 스위칭 오버헤드가 줄어듭니다. 프로세스가 더 오랜 시간 동안 CPU를 사용하기 때문에 스위칭 빈도가 낮아집니다.   
단점: 응답 시간이 길어집니다. 긴 시간을 기다려야 하므로 시스템이 즉각적인 반응을 제공하지 못할 수 있습니다.

</details>

### OS-041
<details>
<summary>싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요?</summary>
<hr>

상시로 돌아가야 하는 프로세스는 일반적으로 우선순위가 높은 작업(예: 실시간 데이터 처리, 시스템 모니터링 등)입니다. 때문에 우선순위 혹은 실시간 스케줄링 알고리즘이 적합합니다.

> Priority Scheduling: 우선순위가 높은 프로세스를 먼저 실행함으로써 이러한 작업이 항상 필요한 CPU 시간을 얻을 수 있도록 보장합니다.

> Real-Time Scheduling: 일정 시간 안에 작업을 반드시 완료해야 하는 실시간 요구가 있는 경우, 정해진 시간 내에 프로세스를 실행하고 완료할 수 있도록 보장할 수 있습니다.

</details>

### OS-042
<details>
<summary>동시성과 병렬성의 차이에 대해 설명해 주세요.</summary>
<hr>

동시성(Concurrency): 여러 작업이 동시에 진행되는 것처럼 보이도록 하는 개념입니다. 실제로는 하나의 CPU가 빠르게 전환하며 여러 작업을 처리하는 방식입니다. 멀티태스킹에서 사용됩니다. 예를 들어, 싱글 코어 시스템에서 스레드가 시분할로 실행되는 경우를 생각할 수 있습니다.

병렬성(Parallelism): 여러 작업이 실제로 동시에 실행되는 것을 의미합니다. 다수의 CPU 코어나 프로세서를 사용하여 여러 작업을 동시에 수행하는 방식입니다. 예를 들어, 멀티코어 CPU에서 여러 스레드가 동시에 실행되는 경우가 있습니다.

</details>

### OS-043
<details>
<summary>타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?</summary>
<hr>

프로세스의 우선순위를 동적으로 조절하며, 오랜 시간동안 대기한 프로세스의 우선순위를 높여서 Starvation(기아)을 완화할 수 있습니다. 또한 CPU를 많이 사용하는 프로세스는 낮은 우선순위로 이동하고, 빠르게 끝나는 프로세스는 높은 우선순위를 유지할 수 있습니다.

> Starvation(기아): 일부 프로세스가 계속해서 높은 우선순위로 실행되면서 다른 프로세스들이 낮은 우선순위로 계속해서 대기하는 상황

</details>

### OS-044
<details>
<summary>FIFO 스케쥴러는 정말 쓸모가 없는 친구일까요? 어떤 시나리오에 사용하면 좋을까요?</summary>
<hr>

응용프로그램이 단순히 모든 작업이 동일한 중요성을 가지고 있고 순서대로 처리해야 하는 경우에 컨텍스트 스위칭 비용이 최소화되기 때문에 적합합니다.

</details>


### OS-045
<details>
<summary>우리는 스케줄링 알고리즘을 "프로세스" 스케줄링 알고리즘이라고 부릅니다. 스레드는 다른 방식으로 스케줄링을 하나요?</summary>
<hr>

운영체제의 스케줄러는 프로세스와 스레드를 모두 스케줄링하여 CPU 시간을 할당합니다.

차이점은 스레드는 같은 프로세스 내에서 실행되며, 메모리 공간과 자원을 공유하기 때문에, 스레드 간의 전환은 더 빠르고 비용이 적습니다.

</details>

### OS-046
<details>
<summary>유저 스레드와 커널 스레드의 스케쥴링 알고리즘은 똑같을까요?</summary>
<hr>

유저 스레드는 커널이 아닌 사용자 공간에서 관리되므로, 스케줄링이 더 빠르고 가볍지만, 커널이 아닌 사용자 레벨의 스레드 라이브러리에서 관리되기 때문에 블록된 스레드가 전체 프로세스에 영향을 미칠 수 있습니다.

반면 커널 스레드는 커널이 개별적으로 관리하여 보다 세밀한 제어가 가능하고, 스레드가 독립적으로 관리되기 때문에 블록된 스레드가 다른 스레드에 영향을 미치지 않습니다. 다만, 커널에서 관리로 인해 스케줄링 오버헤드가 더 큽니다.

> 유저 스레드가 더 빠른 이유: 유저 스레드 라이브러리 자체가 스레드의 레지스터 상태, 스택 포인터 등을 저장하고 복구하는 방식으로 전환. 이 과정은 커널 모드로 전환되지 않고, 유저 모드에서 이루어지기 때문에 상대적으로 가볍고 빠르다.

</details>

## 📌 프로세스 동기화 문제

### OS-047
<details>
<summary>뮤텍스와 세마포어의 차이점은 무엇인가요?</summary>
<hr>

뮤텍스는 하나의 자원에 대해 하나의 소유권(락)만을 가지는 이진 상태로, 자원을 소유한 스레드만이 락을 해제할 수 있습니다. 반면, 세마포어는 소유권의 개념이 없고 여러자원에 대한 동시접근을 세마포어의 정수값으로 제어합니다.

이러한 구조로 인해, 가장 큰 차이는 어떤 환경에서 유리한가 라는 점에서 뮤텍스는 단일자원에서 유리하고 세마포어는 동시에 접근할 수 있는 자원이 여러개일 때 유리합니다.

> 임계구역: 병렬컴퓨팅에서 둘 이상의 스레드가 동시에 접근해서는 안되는 공유 자원

</details>

### OS-048
<details>
<summary>이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.</summary>
<hr>

일반 세마포어는 0과 1이상의 값을 가질 수 있는 반면, 이진 세마포어는 뮤텍스와 유사하게 0과 1만을 가지지만 소유의 개념이 없어 자원을 소유하지 않은 스레드도 세마포어 값을 변경할 수 있습니다.

> 뮤텍스 vs 이진 세마포어   
> 
> 공통점: 둘 다 값이 0 또는 1만 가질 수 있는 락(lock) 역할   
> - 값이 1이면: 자원이 비어 있음(사용 가능)   
> - 값이 0이면: 자원이 누가 쓰는 중(사용 불가)  
>  
> 차이점: 뮤텍스는 소유자(owner)가 있고, 이진 세마포어는 소유자 개념이 없다는 것   
> - 뮤텍스: 누가 이 락을 잡고 있는지(소유자)가 명확   
> - 이진 세마포어: 이진 세마포어도 값은 0/1이지만, “누가 이걸 잡고 있는지”라는 개념이 없음   

</details>

### OS-049
<details>
<summary>Lock을 얻기 위해 대기하는 프로세스들은 Spin Lock 기법을 사용할 수 있습니다. 이 방법의 장단점은 무엇인가요? 단점을 해결할 방법은 없을까요?</summary>
<hr>

> Spin Lock 기법: Lock을 쥐고 있는 동안 대기하는 프로세스가 Lock 변수의 상태를 반복해서 확인하면서(Busy Waiting) 기다리는 방식

CPU가 직접 락을 얻기 위해 대기(Busy Waiting)를 하기 때문에 컨텍스트 스위칭이 발생하지 않아 오버헤드가 적습니다. 때문에, 락이 오래 걸리지 않고 해제가 빠르다면 효율이 좋다는 장점이 있습니다.

다만 자원을 획득할 때까지 CPU를 사용하여 지속적으로 락을 확인하기 때문에, 대기 시간이 길어질수록 CPU의 자원누수가 심해집니다. 이러한 단점을 해결하는 방법으로는 대기 시간이 길어질 수 있는 임계 구역에서는 Spin Lock 대신 뮤텍스 같은 Blocking Lock을 사용하여 해결할 수 있다고 생각합니다.

</details>

### OS-050
<details>
<summary>뮤텍스와 세마포어 모두 커널이 관리하기 때문에, Lock을 얻고 방출하는 과정에서 시스템 콜을 호출해야 합니다. 이 방법의 장단점이 있을까요? 단점을 해결할 수 있는 방법은 없을까요?</summary>
<hr>

자원관리를 시스템콜을 통해 커널이 하는 만큼 안전성을 보장하지만 오버헤드가 발생하는 과정에서의 비용이 단점입니다. 결론은 시스템콜의 수를 줄여야 하는 건데 이를 해소하는 방법으로는 유저스페이스 락을 사용하여 유저모드에서 락을 관리하는 방법입니다.

이에 대한 예시로는 CAS(Compare-and-Swap)나 Fetch-and-Add가 있습니다.

> Compare-and-Swap (CAS): 특정 메모리 위치의 값을 읽고, 예상된 값과 비교한 후, 값이 일치하면 새로운 값으로 원자적으로 변경하는 연산

> Fetch-and-Add: 특정 메모리 주소의 값을 읽고, 그 값을 일정 크기만큼 더한 후 새로운 값을 저장하는 원자적 연산

</details>

### OS-051
<details>
<summary>Deadlock에 대해 설명해 주세요.</summary>
<hr>

교착상태라는 뜻으로 여러 프로세스나 스레드가 서로 자원이 해제되기를 기다리며 대기 상태에 빠지는 상황입니다. 데드락 상황이 발생하면 시스템은 더 이상 진행될 수 없습니다.

</details>

### OS-052
<details>
<summary>Deadlock이 동작하기 위한 4가지 조건에 대해 설명해 주세요.</summary>
<hr>

1. **상호 배제(Mutual Exclusion)**: 자원은 한 번에 하나의 프로세스만 사용할 수 있는 상태입니다.
2. **점유와 대기(Hold and Wait)**: 프로세스가 이미 할당된 자원을 점유하면서, 동시에 다른 자원을 요청하며 기다릴 수 있는 상태입니다.
3. **비선점(Non-Preemption)**: 자원이 한 번 할당되면, 해당 자원은 강제로 회수되지 않으며, 자원을 소유한 프로세스가 자발적으로 자원을 반납할 때까지 다른 프로세스는 해당 자원을 얻을 수 없는 상태입니다.
4. **순환 대기(Circular Wait)**: 여러 프로세스가 서로의 자원을 기다리며 순환적인 대기 상태에 빠집니다. 예를 들어, 프로세스 A가 프로세스 B가 소유한 자원을 기다리고, 프로세스 B는 프로세스 C의 자원을 기다리며, C는 다시 A의 자원을 기다리는 상황이 발생하는 것을 말합니다.

</details>

### OS-053
<details>
<summary>그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?</summary>
<hr>

1. **상호 배제(Mutual Exclusion)**가 없다면: 여러 프로세스가 같은 자원을 동시에 사용할 수 있어 교착 상태가 발생하지 않습니다.
2. **점유와 대기(Hold and Wait)**가 없다면: 프로세스가 추가 자원을 요청할 때 기존 자원을 반납해야 하므로 대기하는 상황이 생기지 않습니다.
3. **비선점(Non-Preemption)**이 없다면: 예를 들어, 어떤 프로세스가 자원을 사용 중일 때, 다른 프로세스가 자원을 요청하면 강제로 자원을 해제할 수 있습니다.
4. **순환 대기(Circular Wait)**가 없다면: 자원이 항상 순차적으로 해제되어 프로세스들이 서로 자원을 기다리는 순환 고리가 형성되지 않기 때문에 Deadlock이 발생하지 않습니다.

</details>

### OS-054
<details>
<summary>어떤 방식으로 예방할 수 있을까요?</summary>
<hr>

1. **상호 배제 조건**: 자원을 여러 프로세스가 동시에 사용할 수 있도록 공유 자원으로 변경합니다.
2. **점유와 대기 조건 방지**: 프로세스가 새 자원을 요청하기 전에, 기존 자원을 모두 반납하도록 강제합니다. 프로세스가 자원을 반납하고 다시 요청해야 하므로 교착 상태를 예방할 수 있습니다.
3. **비선점 방지**: 프로세스가 자원을 사용 중일 때, 강제로 자원을 회수할 수 있도록 설계합니다. 즉, 다른 프로세스가 자원을 요청하면 현재 자원을 소유한 프로세스는 해당 자원을 해제해야 합니다.
4. **순환 대기 방지**: 자원에 순서를 부여하고, 프로세스가 자원을 요청할 때 항상 순서대로 요청하게 합니다.

</details>

### OS-055
<details>
<summary>왜 현대 OS는 Deadlock을 처리하지 않을까요?</summary>
<hr>

교착 상태를 완전히 방지하는 것은 불가능에 가깝고 발생빈도가 잦지 않은데 예방비용으로 많은 리소스를 요구하게 됩니다. 때문에 현실적으로는 데드락 상태를 사람이 느낀 후 직접 조치를 취하는게 더 간단한 해결책일 수 있습니다.

</details>

### OS-056
<details>
<summary>Wait Free와 Lock Free를 비교해 주세요.</summary>
<hr>

Wait-Free는 모든 스레드가 항상 일정 시간 내에 완료되는 것을 보장하는 반면, Lock-Free는 적어도 하나의 스레드가 항상 진전을 이루는 것을 보장하지만, 모든 스레드의 완료 시간을 보장하지는 않습니다.

다만 구현난이도는 Wait Free보다 Lock Free가 더 단순합니다.

> Wait-Free: 모든 스레드가 제한된 시간 내에 작업을 완료할 수 있는 동기화 기법. 즉, 어떠한 스레드도 기다리지 않고 자신의 작업을 끝낼 수 있다.

> Lock-Free: 적어도 하나의 스레드가 항상 작업을 진행할 수 있는 방식. 즉, 전체 스레드가 중단되거나 대기 상태에 빠지지 않도록 보장한다.

</details>

## 📌 컴파일

### OS-057 
<details>
<summary>프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.</summary>
<hr>

1. 사람이 소스 코드(.c, .java 등)를 작성합니다.
2. 컴파일러가 소스 코드를 읽어서 오브젝트 파일(기계어에 가까운 형태)로 바꾸면서 문법 오류 등을 잡습니다.
3. 링커가 여러 오브젝트 파일과 라이브러리들을 하나의 실행 파일로 묶습니다.
4. 로더가 실행 파일을 메모리에 올리고, CPU가 그 안의 기계어를 main()부터 순서대로 실행하면서 프로그램이 실제로 동작하게 됩니다.

> 간단 과정: 소스 코드 작성 -> 컴파일 -> 링크 -> 로드 및 실행

</details>

### OS-058
<details>
<summary>링커와, 로더의 차이에 대해 설명해 주세요.</summary>
<hr>

링커는 여러 오브젝트 파일을 하나의 실행가능한 파일로 만들어줍니다. 여기서 외부 라이브러리나 모듈의 참조를 진행합니다. 

반면, 로더는 링커를 통해 실행가능한 파일을 메모리에 적재하는 역할을 합니다.

즉, 링커는 컴파일단계, 로더는 런타임에 동작하게 됩니다.

</details>

### OS-059
<details>
<summary>컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.</summary>
<hr>

컴파일 언어는 프로그램을 한번에 컴파일하여 실행 파일을 생성하고    
인터프리터는 실행 중에 코드가 한 줄씩 해석되기 때문에 컴파일 언어보다 느립니다.

</details>

### OS-060
<details>
<summary>JIT에 대해 설명해 주세요.</summary>
<hr>

JIT는 실행 중에 코드의 일부를 컴파일하는 방식으로, 인터프리터 언어에서 성능향상을 위해 사용됩니다. Java는 현재 핫스팟 VM으로 자주 사용되는 부분을 실행시점에 기계어로 컴파일하는 방식을 사용하여 성능을 개선합니다.

</details>

### OS-061
<details>
<summary>본인이 사용하는 언어는, 어떤 식으로 컴파일 및 실행되는지 설명해 주세요.</summary>
<hr>

작성한 코드를 자바컴파일러(javac)가 바이트코드로 변환하면 이 바이트코드는 JVM 내에서 실행될 준비가 되어 클래스로더를 통해 메모리로 로드합니다. 그 후, 인터프리터와 JIT컴파일러를 사용하여 바이트코드를 실행합니다.

</details>

### OS-062
<details>
<summary>Python 같은 언어는 CPython, Jython, PyPy등의 다양한 구현체가 있습니다. 각각은 어떤 차이가 있을까요? 또한, 실행되는 과정 또한 다를까요?</summary>
<hr>

> 파이썬의 장점은 개발속도, 생산성, 유연성이 뛰어난 것이라고 생각

Python 구현체들은 Python의 장점을 유지하면서도 한계를 보완하기 위해 사용할 수 있습니다.   
CPython은 기본 인터프리터, Jython은 JVM 기반, PyPy는 JIT 컴파일러 기반으로 동작해 각각의 장단점을 가지고 있습니다.

- CPython: Python 코드를 바이트코드로 컴파일한 후, 인터프리터가 이 바이트코드를 해석하여 실행.
- Jython: Python 코드를 자바 바이트코드로 컴파일한 후, JVM이 이를 실행.
- PyPy: Python 코드를 JIT 컴파일러가 실행 시점에 기계어로 변환하여 성능을 최적화하며 실행.

</details>

### OS-063
<details>
<summary>우리는 흔히 fork(), exec() 시스템 콜을 사용하여 프로세스를 적재할 수 있다고 배웠습니다. 로더의 역할은 이 시스템 콜과 상관있는 걸까요? 아니면 다른 방식으로 프로세스를 적재할 수 있는 건가요?</summary>
<hr>

로더는 메모리에 적재하는 과정이 동반되기 때문에 이 과정에서 exec()가 호출됩니다. 다만 fork()는 현재 프로세스의 메모리공간을 교체하고 새로운 프로세스로 복사하는 시스템콜이기 때문에 로더가 개입되지 않는다고 생각합니다.

</details>
