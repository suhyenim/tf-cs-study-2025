# Operating System (운영체제)

> **목차**    
> [1. 시스템 콜](#1-시스템-콜): 
> [OS-001](#os-001-시스템-콜이-무엇인지-설명해-주세요), [OS-002](#os-002-우리가-사용하는-시스템-콜의-예시를-들어주세요), [OS-003](#os-003-시스템-콜이-운영체제에서-어떤-과정으로-실행되는지-설명해-주세요), [OS-004](#os-004-시스템-콜의-유형에-대해-설명해주세요), [OS-005](#os-005-운영체제의-dual-mode에-대해-설명해주세요), [OS-006](#os-006-왜-유저-모드와-커널-모드를-구분해야-하나요), [OS-007](#os-007-서로-다른-시스템-콜을-어떻게-구분할-수-있을까요)   
> [2. 인터럽트](#2-인터럽트): 
> [OS-008](#os-008-인터럽트가-무엇인지-설명해-주세요), [OS-009](#os-009-인터럽트는-어떻게-처리하나요), [OS-010](#os-010-polling-방식에-대해-설명해-주세요), [OS-011](#os-011-hw--sw-인터럽트에-대해-설명해-주세요), [OS-012](#os-012-동시에-두-개-이상의-인터럽트가-발생하면-어떻게-처리해야-하나요)    
> [3. 프로세스](#3-프로세스): 
> [OS-013](#os-013-프로세스가-무엇인가요), [OS-014](#os-014-프로그램과-프로세스-스레드의-차이에-대해-설명해-주세요), [OS-015](#os-015-pcb가-무엇인가요), [OS-016](#os-016-그렇다면-스레드는-pcb를-갖고-있을까요), [OS-017](#os-017-리눅스에서-프로세스와-스레드는-각각-어떻게-생성될까요), [OS-018](#os-018-자식-프로세스가-상태를-알리지-않고-죽거나-부모-프로세스가-먼저-죽게-되면-어떻게-처리하나요), [OS-019](#os-019-리눅스에서-데몬-프로세스에-대해-설명해-주세요), [OS-020](#os-020-리눅스-프로세스-트리의-루트-노드에-위치하는-프로세스에-대해-설명해-주세요)    
> [3-1. 프로세스 꼬리질문 - 좀비/고아 프로세스](#3-1-프로세스-꼬리질문-좀비고아-프로세스): 
> [꼬리질문1](), [꼬리질문2](), [꼬리질문3](), [꼬리질문4]()     
> [4. 프로세스 주소공간](#4-프로세스-주소공간): 
> [OS-021](#os-021-프로세스-주소공간에-대해-설명해-주세요), [OS-022](#os-022-초기화하지-않은-변수들은-어디에-저장될까요), [OS-023](#os-023-일반적인-주소공간-그림처럼-stack과-heap의-크기는-매우-크다고-할-수-있을까요-그렇지-않다면-그-크기는-언제-결정될까요), [OS-024](#os-024-stack과-heap-공간에-대해-접근-속도가-더-빠른-공간은-어디일까요), [OS-025](#os-025-다음과-같이-공간을-분할하는-이유가-있을까요), [OS-026](#os-026-스레드의-주소공간은-어떻게-구성되어-있을까요), [OS-027](#os-027-스택영역과-힙영역은-정말-자료구조의-스택힙과-연관이-있는-걸까요), [OS-028](#os-028-ipc의-shared-memory-기법은-프로세스-주소공간의-어디에-들어가나요-그런-이유가-있을까요), [OS-029](#os-029-스택과-힙-영역의-크기는-언제-결정되나요-프로그램-개발자가-아닌-사용자가-이-공간의-크기를-수정할-수-있나요)    
> [4-1. 프로세스 주소공간 꼬리질문 - 메모리 관련 문제(Overflow, Leak)](#4-1-프로세스-주소공간-꼬리질문---메모리-관련-문제overflow-leak):
> [꼬리질문1](), [꼬리질문2](), [꼬리질문3](), [꼬리질문4]()  
> [5. CPU 스케줄링](#5-cpu-스케줄링): 
> [OS-030](#os-030-단기-중기-장기-스케줄러에-대해-설명해-주세요), [OS-031](#os-031-현대-os에는-단기-중기-장기-스케줄러를-모두-사용하고-있나요), [OS-032](#os-032-프로세스의-스케줄링-상태에-대해-설명해-주세요), [OS-033](#os-032-프로세스의-스케줄링-상태에-대해-설명해-주세요), [OS-034](#os-034-memory가-부족할-경우-process는-어떠한-상태로-변화할까요)   
> [6. 컨텍스트 스위칭](#6-컨텍스트-스위칭): 
> , [OS-035](#os-035-컨텍스트-스위칭-시에는-어떤-일들이-일어나나요), [OS-036](#os-036-프로세스와-스레드는-컨텍스트-스위칭이-발생했을-때-어떤-차이가-있을까요), [OS-037](#os-037-컨텍스트-스위칭이-발생할-때-기존의-프로세스-정보는-커널스택에-어떠한-형식으로-저장되나요), [OS-038](#os-038-컨텍스트-스위칭은-언제-일어날까요)   
> [7. 스케줄링 알고리즘](#7-스케줄링-알고리즘): 
> [OS-039](#os-039-프로세스-스케줄링-알고리즘에는-어떤-것들이-있나요), [OS-040](#os-040-rr을-사용할-때-time-slice에-따른-trade-off를-설명해-주세요), [OS-041](#os-041-싱글-스레드-cpu-에서-상시로-돌아가야-하는-프로세스가-있다면-어떤-스케쥴링-알고리즘을-사용하는-것이-좋을까요-또-왜-그럴까요), [OS-042](#os-042-동시성과-병렬성의-차이에-대해-설명해-주세요), [OS-043](#os-043-타-스케쥴러와-비교하여-multi-level-feedback-queue는-어떤-문제점들을-해결한다고-볼-수-있을까요), [OS-044](#os-044-fifo-스케쥴러는-정말-쓸모가-없는-친구일까요-어떤-시나리오에-사용하면-좋을까요), [OS-045](#os-045-우리는-스케줄링-알고리즘을-프로세스-스케줄링-알고리즘이라고-부릅니다-스레드는-다른-방식으로-스케줄링을-하나요), [OS-046](#os-046-유저-스레드와-커널-스레드의-스케쥴링-알고리즘은-똑같을까요)    
> [7-1. 스케줄링 알고리즘 꼬리질문 - Round Robin & Multi-level Feedback Queue](#7-1-스케줄링-알고리즘-꼬리질문---round-robin--multi-level-feedback-queue): 
> [꼬리질문1](), [꼬리질문2](), [꼬리질문3](), [꼬리질문4]()  
> [8. 프로세스 동기화 문제](#8-프로세스-동기화-문제): 
> [OS-047](#os-047-뮤텍스와-세마포어의-차이점은-무엇인가요), [OS-048](#os-048-이진-세마포어와-뮤텍스의-차이에-대해-설명해-주세요), [OS-049](#os-049-lock을-얻기-위해-대기하는-프로세스들은-spin-lock-기법을-사용할-수-있습니다-이-방법의-장단점은-무엇인가요-단점을-해결할-방법은-없을까요), [OS-050](#os-050-뮤텍스와-세마포어-모두-커널이-관리하기-때문에-시스템-콜-오버헤드가-있습니다-단점을-해결할-수-있는-방법은-없을까요)    
> [9. 데드락](#9-데드락): 
> [OS-051](#os-051-deadlock-에-대해-설명해-주세요), [OS-052](#os-052-deadlock-이-동작하기-위한-4가지-조건에-대해-설명해-주세요), [OS-053](#os-053-그렇다면-3가지만-충족하면-왜-deadlock-이-발생하지-않을까요), [OS-054](#os-054-어떤-방식으로-예방할-수-있을까요), [OS-055](#os-055-왜-현대-os는-deadlock을-처리하지-않을까요), [OS-056](#os-056-wait-free와-lock-free를-비교해-주세요)    
> [10. 컴파일](#10-컴파일):
> [OS-057](#os-057-프로그램이-컴파일-되어-실행되는-과정을-간략하게-설명해-주세요), [OS-058](#os-058-링커와-로더의-차이에-대해-설명해-주세요), [OS-059](#os-059-컴파일-언어와-인터프리터-언어의-차이에-대해-설명해-주세요), [OS-060](#os-060-jit에-대해-설명해-주세요), [OS-061](#os-061-본인이-사용하는-언어는-어떤식으로-컴파일-및-실행되는지-설명해-주세요), [OS-062](#os-062-python-같은-언어는-cpython-jython-pypy등의-다양한-구현체가-있습니다-각각은-어떤-차이가-있을까요-또한-실행되는-과정-또한-다를까요), [OS-063](#os-063-우리는-흔히-fork-exec-시스템-콜을-사용하여-프로세스를-적재할-수-있다고-배웠습니다-로더의-역할은-이-시스템-콜과-상관있는-걸까요-아니면-다른-방식으로-프로세스를-적재할-수-있는-건가요)   
> [11. IPC](#11-ipc): 
> [OS-064](#os-064-ipc가-무엇이고-어떤-종류가-있는지-설명해-주세요), [OS-065](#os-065-shared-memory가-무엇이며-사용할-때-유의해야-할-점에-대해-설명해-주세요), [OS-066](#os-066-메시지-큐는-단방향이라고-할-수-있나요)    
> [12. 스레드 안전](#12-스레드-안전): 
> [OS-067](#os-067-thread-safe-하다는-것은-어떤-의미인가요), [OS-068](#os-068-thread-safe-를-보장하기-위해-어떤-방법을-사용할-수-있나요), [OS-069](#os-069-petersons-algorithm-이-무엇이며-한계점에-대해-설명해-주세요), [OS-070](#os-070-race-condition-이-무엇인가요), [OS-071](#os-071-thread-safe를-구현하기-위해-반드시-락을-사용해야-할까요-그렇지-않다면-어떤-다른-방법이-있을까요)     
> [13. Thread Pool, Monitor, Fork-Join](#13-thread-pool-monitor-fork-join): 
> [OS-072](#os-072-thread-pool-monitor-fork-join에-대해-설명해-주세요), [OS-073](#os-073-thread-pool을-사용한다고-가정하면-어떤-기준으로-스레드의-수를-결정할-것인가요), [OS-074](#os-074-어떤-데이터를-정렬-하려고-합니다-어떤-방식의-전략을-사용하는-것이-가장-안전하면서도-좋은-성능을-낼-수-있을까요)    
> [14. 캐시 메모리](#14-캐시-메모리): 
> [OS-075](#os-075-캐시-메모리-및-메모리-계층성에-대해-설명해-주세요), [OS-076](#os-076-캐시-메모리는-어디에-위치해-있나요), [OS-077](#os-077-l1-l2-캐시에-대해-설명해-주세요), [OS-078](#os-078-캐시에-올라오는-데이터는-어떻게-관리되나요), [OS-079](#os-079-캐시간의-동기화는-어떻게-이루어지나요), [OS-080](#os-080-캐시-메모리의-mapping-방식에-대해-설명해-주세요), [OS-081](#os-081-캐시의-지역성에-대해-설명해-주세요), [OS-082](#os-082-캐시의-지역성을-기반으로-이차원-배열을-가로세로로-탐색했을-때의-성능-차이에-대해-설명해-주세요), [OS-083](#os-083-캐시의-공간-지역성은-어떻게-구현될-수-있을까요-힌트-캐시는-어떤-단위로-저장되고-관리될까요)   
> [14-1. 캐시메모리 꼬리질문 - 캐시 일관성 (Cache Coherency)](#14-1-캐시-메모리-꼬리질문---캐시-일관성-cache-coherency): 
> [꼬리질문1](), [꼬리질문2](), [꼬리질문3](), [꼬리질문4]()     
> [15. 메모리 할당 기법](#15-메모리-할당-기법): 
> [OS-084](#os-084-연속할당-방식-세-가지를-설명해주세요-first-fit-best-fit-worst-fit), [OS-085](#os-085-worst-fit-은-언제-사용할-수-있을까요), [OS-086](#os-086-성능이-가장-좋은-알고리즘은-무엇일까요)     
> [16. Thrashing](#16-thrashing): 
> [OS-087](#os-087-thrashing-이란-무엇인가요), [OS-088](#os-088-thrashing-발생-시-어떻게-완화할-수-있을까요)     
> [17. 가상 메모리](#17-가상-메모리): 
> [OS-089](#os-089-가상-메모리란-무엇인가요), [OS-090](#os-090-가상-메모리가-가능한-이유가-무엇일까요), [OS-091](#os-091-page-fault가-발생했을-때-어떻게-처리하는지-설명해-주세요), [OS-092](#os-091-page-fault가-발생했을-때-어떻게-처리하는지-설명해-주세요), [OS-093](#os-093-페이지-크기가-커지면-페이지-폴트가-더-많이-발생한다고-할-수-있나요), [OS-094](#os-094-세그멘테이션-방식을-사용하고-있다면-가상-메모리를-사용할-수-없을까요)      
> [18. 세그멘테이션 & 페이징](#18-세그멘테이션--페이징): 
> [OS-095](#os-095-세그멘테이션과-페이징의-차이점은-무엇인가요), [OS-096](#os-096-페이지와-프레임의-차이에-대해-설명해-주세요), [OS-097](#os-097-내부-단편화와-외부-단편화에-대해-설명해-주세요), [OS-098](#os-098-페이지에서-실제-주소를-어떻게-가져올-수-있는지-설명해-주세요), [OS-099](#os-099-어떤-주소공간이-있을-때-이-공간이-수정-가능한지-확인할-수-있는-방법이-있나요), [OS-100](#os-100-32비트에서-페이지의-크기가-1kb-이라면-페이지-테이블의-최대-크기는-몇-개일까요), [OS-101](#os-101-32비트-운영체제는-램을-최대-4g-까지-사용할-수-있습니다-이-이유를-페이징과-연관-지어서-설명해-주세요), [OS-102](#os-102-cc-개발-시-segmentation-fault-에러는-세그멘테이션페이징과-어떤-관계가-있을까요)   
> [18-1. 세그멘테이션 & 페이징 꼬리질문 - 페이징과 세그멘테이션의 차이](#18-1-세그멘테이션--페이징---페이징과-세그멘테이션의-차이): 
> [꼬리질문1](), [꼬리질문2](), [꼬리질문3](), [꼬리질문4]()  
> [19. TLB](#19-tlb): 
> [OS-103](#os-103-tlb는-무엇인가요), [OS-104](#os-104-tlb를-쓰면-왜-빨라지나요), [OS-105](#os-105-mmu가-무엇인가요), [OS-106](#os-106-tlb와-mmu는-어디에-위치해-있나요), [OS-107](#os-107-코어가-여러개라면-tlb는-어떻게-동기화-할-수-있을까요), [OS-108](#os-108-tlb-관점에서-context-switching-발생-시-어떤-변화가-발생하는지-설명해-주세요)   
> [20. 동기화 구현](#20-동기화-구현): 
> [OS-109](#os-109-동기화를-구현하기-위한-하드웨어적인-해결-방법에-대해-설명해-주세요), [OS-110](#os-110-volatile-키워드는-어떤-의미가-있나요), [OS-111](#os-111-싱글코어가-아니라-멀티코어라면-어떻게-동기화가-이뤄질까요)   
> [21. 페이징 알고리즘](#21-페이징-알고리즘):
> [OS-112](#os-112-페이지-교체-알고리즘에-대해-설명해-주세요), [OS-113](#os-113-lru-알고리즘은-어떤-특성을-이용한-알고리즘이라고-할-수-있을까요), [OS-114](#14-1-캐시-메모리-꼬리질문---캐시-일관성-cache-coherency), [OS-115](#os-115-lru-알고리즘의-단점을-설명해-주세요-이를-해결할-수-있는-대안에-대해서도-설명해-주세요)   
> [21-1. 페이징 알고리즘 꼬리질문 - Clock 알고리즘](#21-1-페이징-알고리즘-꼬리질문---clock-알고리즘): 
> [꼬리질문1](), [꼬리질문2](), [꼬리질문3](), [꼬리질문4]()    
> [22. 파일 시스템 및 I/O](#22-파일-시스템-및-io): 
> [OS-116](#os-116-file-descriptor와-file-system에-대해-설명해-주세요), [OS-117](#os-117-i-node가-무엇인가요), [OS-118](#os-118-프로그래밍-언어-상에서-제공하는-파일-관련-함수는-파일을-어떤-방식으로-읽어들이나요)        
> [23. 동기 & 비동기](#23-동기--비동기): 
> [OS-119](#os-119-동기와-비동기-블로킹과-논블로킹의-차이에-대해-설명해-주세요), [OS-120](#os-120-그렇다면-동기이면서-논블로킹이고-비동기이면서-블로킹인-경우는-의미가-있다고-할-수-있나요), [OS-121](#21-1-페이징-알고리즘-꼬리질문---clock-알고리즘), [OS-122](#os-122-논블로킹-io를-수행한다고-하면-그-결과를-어떻게-수신할-수-있나요)    
> [23-1. 동기 & 비동기 꼬리질문 - I/O 멀티플렉싱의 구현 방식과 Redis의 성능 비결](#23-1-동기--비동기-꼬리질문---io-멀티플렉싱의-구현-방식과-redis의-성능-비결):
> [꼬리질문1](), [꼬리질문2](), [꼬리질문3](), [꼬리질문4]()    


# 1. 시스템 콜

### OS-001. 시스템 콜이 무엇인지 설명해 주세요.
사용자 모드의 프로그램이 **커널 모드의 기능(파일 I/O, 프로세스 생성 등)을 사용하기 위해 운영체제에 요청하는 인터페이스**입니다.

### OS-002. 우리가 사용하는 시스템 콜의 예시를 들어주세요.
대표적으로 프로세스를 생성하고 제어하는 **`fork()`, `exec()`, `exit()`**와 파일 내용을 읽거나 쓰는 **`open()`, `read()`, `write()`** 등이 있습니다.

### OS-003. 시스템 콜이 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.
사용자 프로그램이 인터럽트를 발생시키면 CPU는 **유저 모드에서 커널 모드로 전환**됩니다. 
이후 IDT(인터럽트 벡터 테이블)를 참조하여 해당 시스템 콜 번호에 맞는 커널 함수를 실행한 뒤, 다시 유저 모드로 복귀합니다.

### OS-004. 시스템 콜의 유형에 대해 설명해주세요.
시스템 콜은 기능에 따라 크게 프로세스 제어, 파일 조작, 장치 관리, 정보 유지, 통신, 보호의 6가지 유형으로 분류됩니다.

### OS-005. 운영체제의 Dual Mode에 대해 설명해주세요.
시스템 보호를 위해 제한된 권한만 갖는 실행 모드인 **유저 모드(User Mode)**와 
모든 시스템 자원에 접근 가능한 **커널 모드(Kernel Mode)**로 나누어 관리하는 방식입니다.

### OS-006. 왜 유저 모드와 커널 모드를 구분해야 하나요?
사용자 프로그램이 잘못된 명령으로 **중요한 운영체제 영역이나 하드웨어 자원을 훼손하는 것을 방지**하여, 
시스템 전체의 안정성과 보안을 유지하기 위함입니다.

### OS-007. 서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?
각 시스템 콜마다 고유한 **시스템 콜 번호(System Call Number)**가 부여되어 있으며, 커널은 레지스터에 저장된 이 번호를 읽어 어떤 기능을 수행해야 할지 식별합니다.

## 2. 인터럽트

### OS-008. 인터럽트가 무엇인지 설명해 주세요.
인터럽트는 하드웨어 장치나 소프트웨어 프로그램이 **CPU에게 보내는 신호**로, 
현재 실행 중인 작업을 잠시 중단하고 예외 상황이나 입출력 이벤트를 즉시 처리하도록 요청하는 메커니즘입니다.

### OS-009. 인터럽트는 어떻게 처리하나요?
CPU는 현재 작업 상태(Context)를 저장한 후, **인터럽트 벡터 테이블(IDT)**을 참조하여 해당 이벤트에 맞는 처리 함수(ISR: 인터럽트 서비스 루틴)를 실행하고 다시 원래 작업으로 복귀합니다.

### OS-010. Polling 방식에 대해 설명해 주세요.
인터럽트와 달리, CPU가 입출력 장치 등의 상태를 **주기적으로 계속 확인(Loop)하여 작업 완료 여부를 파악하는 방식**입니다. 구현은 쉽지만 불필요한 확인으로 CPU 자원 낭비가 발생할 수 있습니다.

### OS-011. HW / SW 인터럽트에 대해 설명해 주세요.
**HW 인터럽트**는 키보드, 마우스, 타이머 등 외부 하드웨어 장치가 보내는 신호이며, 
**SW 인터럽트(Trap)**는 0으로 나누기 오류나 시스템 콜 호출처럼 프로그램 코드 실행 중에 발생하는 내부 신호입니다.

### OS-012. 동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?
각 인터럽트에 부여된 **우선순위(Priority)**에 따라 중요한 것을 먼저 처리하거나, 현재 처리 중인 인터럽트가 끝날 때까지 다른 인터럽트를 대기시키는 방식으로 처리합니다.

## 3. 프로세스

### OS-013. 프로세스가 무엇인가요?
운영체제로부터 자원을 할당받아 **메모리에 적재되어 실행 중인 프로그램(Program in execution)**을 의미합니다.

### OS-014. 프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.
**프로그램**은 디스크에 저장된 정적인 코드 파일이고, **프로세스**는 이를 메모리에 올려 실행하는 작업의 단위이며, 
**스레드**는 프로세스 내에서 자원을 공유하며 실행되는 **흐름의 단위**입니다.

### OS-015. PCB가 무엇인가요?
**Process Control Block**의 약자로, 프로세스 상태, PC(프로그램 카운터), 레지스터 값 등 
운영체제가 **프로세스를 관리하기 위해 필요한 모든 정보를 저장하는 커널 내 자료구조**입니다.

### OS-016. 그렇다면, 스레드는 PCB를 갖고 있을까요?
스레드는 프로세스의 자원을 공유하되 실행 흐름은 독립적이므로, **TCB(Thread Control Block)**라는 별도의 자료구조를 통해 스택과 레지스터 정보를 개별적으로 관리합니다. 
(리눅스에서는 PCB와 TCB를 `task_struct`라는 동일한 구조체로 관리하기도 합니다.)

### OS-017. 리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?
프로세스는 **`fork()`** 시스템 콜을 통해 부모 프로세스를 복제하여 생성하고, 
스레드는 **`clone()`** 시스템 콜을 통해 메모리 공간을 공유하는 방식으로 생성됩니다.

### OS-018. 자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?
종료되었으나 부모가 회수(`wait`)하지 않은 자식은 **좀비 프로세스**가 되고, 
부모가 먼저 종료된 자식은 **고아 프로세스**가 되어 **`init` 프로세스(PID 1)**가 입양하여 안전하게 종료시킵니다.

### OS-019. 리눅스에서, 데몬 프로세스에 대해 설명해 주세요.
사용자와 직접 상호작용하지 않고 **백그라운드에서 계속 실행**되면서 서버 역할이나 시스템 관리 작업을 수행하는 프로세스입니다.

### OS-020. 리눅스 프로세스 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.
**PID 1번을 갖는 `init` 프로세스(최신 리눅스에서는 `systemd`)**로, 부팅 시 커널에 의해 최초로 생성되어 나머지 모든 사용자 프로세스를 생성하고 관리하는 **조상 프로세스**입니다.

## 3-1. 프로세스 꼬리질문: 좀비/고아 프로세스 

### 꼬리질문1. 좀비 프로세스(Zombie Process)가 정확히 무엇인가요?
프로세스의 실행은 종료되어 메모리 자원은 반납했지만, 부모 프로세스가 아직 종료 상태를 회수(`wait`)하지 않아 **프로세스 테이블(PCB)에 PID와 종료 코드 등 최소한의 정보가 지워지지 않고 남아있는 상태**입니다.

### 꼬리질문2. 좀비 프로세스가 쌓이면 시스템에 치명적인가요?
메모리나 CPU를 사용하지는 않지만, 한정된 자원인 **PID(프로세스 ID)를 계속 점유**하기 때문에, 너무 많이 쌓이면 새로운 프로세스를 생성할 수 없게 되는 문제가 발생합니다.

### 꼬리질문3. 그럼 좀비 프로세스는 `kill` 명령어로 죽일 수 있나요?
아니요, 이미 죽은 상태(Dead)이기 때문에 **`kill` 명령어가 통하지 않습니다.** 이를 없애려면 부모 프로세스가 `wait` 시스템 콜을 호출하게 하거나, 부모 프로세스를 아예 종료시켜야 합니다.

### 꼬리질문4. 부모 프로세스를 죽이면 좀비 프로세스는 어떻게 되나요?
부모가 종료되면 해당 좀비 프로세스는 **`init` 프로세스(PID 1)**에게 **입양(부모 변경)**됩니다. `init` 프로세스는 주기적으로 자식의 종료를 확인하므로, 입양된 좀비 프로세스를 발견하는 즉시 메모리에서 제거(`wait`)하여 좀비 상태를 해소합니다.

## 4. 프로세스 주소공간

### OS-021. 프로세스 주소공간에 대해 설명해 주세요.
프로세스가 실행될 때 메모리(RAM) 상에 할당받는 가상 공간으로, 크게 **코드(Code), 데이터(Data), 힙(Heap), 스택(Stack)** 네 가지 영역으로 구분됩니다.

### OS-022. 초기화하지 않은 변수들은 어디에 저장될까요?
데이터 영역 내의 **BSS(Block Started by Symbol) 영역**에 저장됩니다. 초기화된 전역 변수는 Data 영역에, 초기화되지 않은 전역 변수는 BSS 영역에 저장되어 `0`으로 자동 초기화됩니다.

### OS-023. 일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?
그림은 가상 메모리의 **최대 범위**를 나타낼 뿐, 실제로는 운영체제가 **필요한 만큼만 물리 메모리를 할당**하므로 초기 크기는 크지 않습니다. **스택**은 프로세스 생성 시(혹은 OS 설정 `ulimit`) 최대 크기가 고정되며, **힙**은 런타임에 동적 할당 요청(`malloc`)이 들어올 때마다 크기가 결정되고 늘어납니다.

### OS-024. Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?
**Stack이 더 빠릅니다.** 
Stack은 메모리 할당/해제가 단순히 포인터 위치만 옮기면 되고 데이터가 연속적이어서 캐시 적중률(Cache Hit)이 높은 
반면, Heap은 빈 공간을 탐색하고 관리하는 복잡한 과정이 필요하기 때문입니다.

### OS-025. 다음과 같이 공간을 분할하는 이유가 있을까요?
데이터의 성격(정적/동적, 공유 가능/불가능)에 따라 **효율적으로 관리하고 공유하기 위함**입니다. 
예를 들어, 읽기 전용인 Code 영역은 여러 프로세스가 공유하여 메모리를 아끼고, Stack/Heap 영역은 실행 흐름에 맞춰 독립적으로 관리합니다.

### OS-026. 스레드의 주소공간은 어떻게 구성되어 있을까요?
같은 프로세스 내의 스레드들은 **Code, Data, Heap 영역을 서로 공유**합니다. 하지만 독립적인 실행 흐름을 위해 **Stack 영역(과 레지스터)**만큼은 각 스레드가 개별적으로 가집니다.

### OS-027. "스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요?
**Stack 영역**은 함수 호출 시 LIFO(Last In First Out) 방식으로 동작하므로 **자료구조 스택과 일치**합니다. 
반면, **Heap 영역**은 자유롭게 메모리를 할당하는 풀(Pool)을 의미할 뿐, 우선순위 큐인 **자료구조 힙(Heap)과는 직접적인 관련이 없습니다.**

### OS-028. IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요?
주로 **Heap 영역과 Stack 영역 사이의 공간(Mmap 영역)**에 매핑됩니다. 이 공간은 크기가 유동적이고 런타임에 동적으로 할당받아 쓰기에 적합하기 때문입니다.

### OS-029. 스택과 힙 영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요?
**스택**은 프로세스 생성 시점에 최대 크기가 결정되고, **힙**은 프로그램 실행 중(런타임)에 동적으로 크기가 결정됩니다. 사용자는 리눅스의 `ulimit` 명령어나 시스템 설정을 통해 스택의 크기 제한이나 프로세스의 최대 메모리 사용량을 직접 수정할 수 있습니다.

## 4-1. 프로세스 주소공간 꼬리질문 - 메모리 관련 문제(Overflow, Leak)

### 꼬리질문1. 스택 오버플로우(Stack Overflow)는 언제 발생하나요?
스택 영역에 할당된 메모리 한계를 초과하여 데이터가 저장될 때 발생합니다. 주로 **재귀 함수의 무한 호출**이 발생하거나 함수 내부에 **지나치게 큰 지역 변수(배열 등)**를 선언했을 때 일어납니다.

### 꼬리질문2. 힙 오버플로우(Heap Overflow)는 무엇이고 왜 위험한가요?
힙 영역에 할당된 버퍼 크기보다 더 많은 데이터를 입력할 때, 인접한 메모리 공간을 덮어쓰는 현상입니다. 이를 악용해 **중요한 데이터를 변조하거나 특정 코드를 실행(Exploit)**하게 만들 수 있어 보안상 매우 위험합니다.

### 꼬리질문3. 메모리 누수(Memory Leak)란 무엇인가요?
동적으로 할당받은 메모리(Heap)를 다 사용한 후에 **해제(Free)하지 않아, 시스템 메모리가 계속 점유된 상태로 낭비되는 현상**입니다. 누수가 누적되면 결국 시스템의 가용 메모리가 고갈되어 성능 저하나 멈춤 현상이 발생합니다.

### 꼬리질문4. 메모리가 부족해지면(OOM) 운영체제는 어떻게 대응하나요?
리눅스의 경우 **OOM Killer(Out of Memory Killer)**가 동작하여, 시스템 안정성을 위해 메모리를 많이 사용하는 프로세스 등을 강제로 **종료(Kill)**시켜 여유 공간을 확보합니다.

## 5. CPU 스케줄링

### OS-030. 단기, 중기, 장기 스케줄러에 대해 설명해 주세요.
**장기 스케줄러**는 어떤 작업을 하드디스크에서 메모리로 가져올지(Job Scheduling) 결정하고, 
**단기 스케줄러**는 메모리에 있는 프로세스 중 누구에게 CPU를 줄지(CPU Scheduling) 결정합니다. 
**중기 스케줄러**는 메모리 부족 시 프로세스를 디스크로 쫓아내거나(Swap-out) 다시 불러와 메모리 여유 공간을 확보하는 역할을 합니다.

### OS-031. 현대 OS에는 단기, 중기, 장기 스케줄러를 모두 사용하고 있나요?
현대 운영체제는 프로세스 생성 시 즉시 메모리에 적재하므로 **장기 스케줄러는 거의 사용하지 않습니다**. 대신 CPU 자원을 관리하는 **단기 스케줄러**와, 메모리 부족 시 스와핑을 담당하는 **중기 스케줄러**를 주로 사용합니다.

### OS-032. 프로세스의 스케줄링 상태에 대해 설명해 주세요.
프로세스는 생성(New), 준비(Ready), 실행(Running), 대기(Waiting/Blocked), 종료(Terminated)의 5가지 상태를 오가며 실행됩니다. 여기에 메모리 부족으로 디스크로 쫓겨난 상태인 **보류(Suspended)** 상태가 추가되기도 합니다.

### OS-033. preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?
**비선점형(Non-preemptive)** 스케줄링에서는 프로세스가 스스로 CPU를 반납하기 전까지는 강제로 뺏기지 않으므로, **'Running → Ready'로 강제로 이동하는 상태 전이가 존재하지 않습니다.** 
반면 선점형에서는 타임 슬라이스 만료 시 이 경로로 이동합니다.

### OS-034. Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?
중기 스케줄러에 의해 메모리에서 디스크의 스왑 영역(Swap Area)으로 쫓겨나면서 **보류 상태(Suspended State)**가 됩니다. 이때 원래 상태에 따라 '보류된 준비(Suspended Ready)' 혹은 '보류된 대기(Suspended Blocked)' 상태로 구분됩니다.

## 6. 컨텍스트 스위칭

### OS-035. 컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?
현재 실행 중인 프로세스의 **문맥(레지스터 값, PC 등)을 PCB에 저장**하고, 다음에 실행할 프로세스의 저장된 문맥을 다시 레지스터로 복구하는 작업이 수행됩니다. 이 과정에서 CPU 캐시가 초기화되거나 TLB가 비워지는 등의 오버헤드가 발생합니다.

### OS-036. 프로세스와 스레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?
**프로세스**는 가상 메모리 주소 공간 전체를 전환해야 해서 캐시/TLB 초기화 비용이 크지만, 
**스레드**는 메모리(Code, Data, Heap)를 공유하므로 **레지스터와 스택 포인터 등 최소한의 정보만 교체**하면 되어 훨씬 빠르고 가볍습니다.

### OS-037. 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?
CPU의 범용 레지스터, 프로그램 카운터(PC), 상태 레지스터 값들이 **`pt_regs` 같은 구조체 형태**로 커널 스택의 최상단에 순차적으로 **푸시(Push)**되어 저장됩니다.

### OS-038. 컨텍스트 스위칭은 언제 일어날까요?
멀티태스킹을 위해 할당된 **시간(Time Slice)이 만료**되었거나(Timer Interrupt), **I/O 요청**으로 인해 대기(Block) 상태로 전환될 때, 혹은 더 높은 우선순위의 프로세스가 등장했을 때 발생합니다.

## 7. 스케줄링 알고리즘

### OS-039. 프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?
대표적으로 도착 순서대로 처리하는 **FCFS**, 짧은 작업을 먼저 하는 **SJF**, 정해진 시간만큼 돌아가며 쓰는 **Round Robin(RR)**, 그리고 우선순위와 큐를 조합한 **Multi-level Feedback Queue(MLFQ)** 등이 있습니다.

### OS-040. RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.
타임 슬라이스가 **너무 크면 FCFS와 같아져** 응답 속도가 느려지고, **너무 작으면 잦은 문맥 교환(Context Switch)**으로 인한 오버헤드가 커져 시스템 전체 성능이 저하됩니다.

### OS-041. 싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요?
**Round Robin(RR)** 방식이 적합합니다. 한 프로세스가 CPU를 독점하지 않게 하여, 상시로 돌아가는 프로세스도 일정 시간마다 반드시 CPU를 할당받아 **응답성(Responsiveness)**을 유지할 수 있기 때문입니다.

### OS-042. 동시성과 병렬성의 차이에 대해 설명해 주세요.
**동시성(Concurrency)**은 싱글 코어에서 여러 작업을 번갈아 빠르게 실행해 **동시에 실행되는 것처럼 보이게** 하는 논리적 개념이고, **병렬성(Parallelism)**은 멀티 코어에서 실제로 여러 작업을 **물리적으로 동시에** 실행하는 것입니다.

### OS-043. 타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?
실행 시간을 미리 알아야 하는 SJF의 비현실적인 가정을 해결하고, 입출력 중심 작업(I/O Bound)에는 빠른 응답을, CPU 중심 작업에는 충분한 시간을 할당하여 **응답성과 처리 효율**을 모두 잡았습니다.

### OS-044. FIFO 스케쥴러는 정말 쓸모가 없는 친구일까요? 어떤 시나리오에 사용하면 좋을까요?
아니요, 문맥 교환 오버헤드가 적기 때문에 사용자와 상호작용이 없고 순차적 처리가 중요한 **일괄 처리(Batch Processing) 시스템**에서는 가장 효율적입니다.

### OS-045. 우리는 스케줄링 알고리즘을 "프로세스" 스케줄링 알고리즘이라고 부릅니다. 스레드는 다른 방식으로 스케줄링을 하나요?
현대 운영체제(Linux 등)에서는 **스케줄링의 단위가 스레드(Kernel Thread)**입니다. 따라서 프로세스 스케줄링 알고리즘이 실제로는 각 스레드를 대상으로 동일하게 적용됩니다.

### OS-046. 유저 스레드와 커널 스레드의 스케쥴링 알고리즘은 똑같을까요?
다릅니다. **커널 스레드**는 운영체제 스케줄러가 관리하지만, **유저 스레드**는 사용자 라이브러리(런타임)가 자체 정책으로 관리하며 커널 입장에서는 하나의 프로세스로만 보입니다.

## 7-1. 스케줄링 알고리즘 꼬리질문 - Round Robin & Multi-level Feedback Queue

### 꼬리질문1. 라운드 로빈(Round Robin)에서 할당 시간(Time Quantum)을 어떻게 정하는 것이 좋은가요?
할당 시간이 **너무 크면** 먼저 온 프로세스가 다 끝날 때까지 기다리는 **FCFS(선착순)** 방식과 다를 바 없어 응답 속도가 느려지고, **너무 작으면** 잦은 **문맥 교환(Context Switch)**으로 인해 오버헤드가 커져 시스템 성능이 저하됩니다. 따라서 문맥 교환 비용과 응답 시간 사이의 균형을 맞추는 것이 중요합니다.

### 꼬리질문2. MLFQ(Multi-level Feedback Queue)는 어떤 문제를 해결하기 위해 등장했나요?
짧은 작업에 우선순위를 주면서도 긴 작업이 계속 실행될 수 있도록, **여러 개의 큐**를 두고 프로세스의 CPU 사용 패턴에 따라 **동적으로 우선순위를 조정**하기 위해 등장했습니다. 입출력 위주의 작업은 상위 큐에서 빠르게 처리하고, CPU 연산 위주의 작업은 하위 큐로 내려보내는 방식입니다.

### 꼬리질문3. MLFQ에서 하위 큐에 있는 프로세스가 영원히 실행되지 못하는 '기아 현상(Starvation)'이 발생할 수 있는데, 해결책은 무엇인가요?
일정 시간이 지나면 하위 큐에 대기 중인 모든 프로세스의 우선순위를 최상위 큐로 리셋해주는 **에이징(Aging) 기법**을 사용하여 해결합니다. 이를 통해 오래 기다린 프로세스도 반드시 CPU를 할당받도록 보장합니다.

### 꼬리질문4. 왜 이름에 'Feedback'이 들어가나요?
프로세스가 CPU를 얼마나 사용했는지 관찰하고, 그 결과(Feedback)를 바탕으로 **다음 번 우선순위(어느 큐로 보낼지)를 결정**하기 때문입니다.

## 8. 프로세스 동기화 문제

### OS-047. 뮤텍스와 세마포어의 차이점은 무엇인가요?
**뮤텍스**는 락을 가진 스레드만 해제할 수 있는 **상호 배제(Locking)** 기법(1개 허용)이고, **세마포어**는 카운터 변수를 활용해 정해진 개수만큼의 스레드 접근을 허용하는 **신호(Signaling)** 기법입니다.

### OS-048. 이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.
가장 큰 차이는 **소유권(Ownership)** 여부입니다. 뮤텍스는 락을 건 스레드만이 락을 풀 수 있지만, 세마포어는 소유권이 없어 **다른 스레드가 신호를 보내(Signal) 락을 해제**할 수 있습니다.

### OS-049. Lock을 얻기 위해 대기하는 프로세스들은 Spin Lock 기법을 사용할 수 있습니다. 이 방법의 장단점은 무엇인가요? 단점을 해결할 방법은 없을까요?
문맥 교환 비용이 없다는 장점이 있지만, 대기하는 동안 **CPU를 계속 점유(Busy Waiting)하여 자원을 낭비**한다는 치명적인 단점이 있습니다. 이를 해결하기 위해 일정 시간만 스핀하다가 **슬립(Sleep) 상태로 전환**하는 방식을 사용합니다.

### OS-050. 뮤텍스와 세마포어 모두 커널이 관리하기 때문에 시스템 콜 오버헤드가 있습니다. 단점을 해결할 수 있는 방법은 없을까요?
경쟁이 없을 때는 가벼운 유저 모드 원자적 연산(CAS)으로 처리하고, 경쟁이 발생했을 때만 커널 시스템 콜을 호출하는 **Futex(Fast Userspace Mutex)** 방식을 사용하여 성능을 최적화합니다.

## 9. 데드락

### OS-051. Deadlock 에 대해 설명해 주세요.
두 개 이상의 프로세스가 서로 상대방이 가진 자원을 점유하고 놓아주지 않아, **모두가 무한히 대기하며 멈춰버린 상태**를 말합니다.

### OS-052. Deadlock 이 동작하기 위한 4가지 조건에 대해 설명해 주세요.
자원은 한 번에 하나만 쓸 수 있고(**상호 배제**), 자원을 쥔 채 다른 것을 기다리며(**점유 대기**), 남의 것을 뺏을 수 없고(**비선점**), 꼬리를 물고 기다리는(**환형 대기**) 4가지 조건이 동시에 성립해야 합니다.

### OS-053. 그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?
데드락은 이 **4가지 조건이 모두 만족해야만 성립하는 필요충분조건**이기 때문입니다. 예를 들어 환형 대기 고리만 끊어줘도 프로세스들이 순차적으로 자원을 쓰고 반납하여 교착 상태가 풀립니다.

### OS-054. 어떤 방식으로 예방할 수 있을까요?
4가지 조건 중 하나를 무력화하면 되는데, 현실적으로는 모든 자원에 번호를 매기고 오름차순으로만 요청하게 하여 **환형 대기(Circular Wait) 조건을 방지**하는 방법이 주로 쓰입니다.

### OS-055. 왜 현대 OS는 Deadlock을 처리하지 않을까요?
데드락을 완벽히 방지하거나 감지하는 비용이 발생 빈도에 비해 **너무 비싸고 비효율적**이기 때문입니다. 데드락이 발생하면 사용자가 프로세스를 종료하거나 재부팅하는 것이 경제적이라고 판단하는 **타조 알고리즘(Ostrich Algorithm)**을 채택했습니다.

### OS-056. Wait Free와 Lock Free를 비교해 주세요.
**Lock Free**는 시스템 전체 관점에서 적어도 하나의 스레드는 계속 진행됨을 보장하며, **Wait Free**는 더 강력한 조건으로 **모든 스레드가 유한한 단계(Starvation 없음) 내에 작업을 완료함**을 보장합니다.

## 10. 컴파일 

### OS-057. 프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.
소스 코드는 **전처리 → 컴파일 → 어셈블 → 링크** 과정을 거쳐 기계어인 실행 파일(.exe)이 되고, 실행 시 로더가 이를 메모리에 적재하면 CPU가 명령어를 처리합니다.

### OS-058. 링커와, 로더의 차이에 대해 설명해 주세요.
**링커**는 여러 코드 조각(오브젝트 파일, 라이브러리)을 엮어 하나의 **실행 파일을 디스크에 만드는 역할**을 하고, **로더**는 그 실행 파일을 읽어 **메모리에 올리는 역할**을 합니다.

### OS-059. 컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.
**컴파일 언어(C, C++)**는 소스 전체를 미리 기계어로 번역해 실행하므로 **속도가 빠르고**, **인터프리터 언어(Python, JS)**는 런타임에 한 줄씩 해석하므로 **수정은 유연하나 속도가 상대적으로 느립니다.**

### OS-060. JIT에 대해 설명해 주세요.
인터프리터의 느린 속도를 보완하기 위해, 실행 중에 **자주 사용되는 코드(Hot Spot)를 실시간으로 기계어로 컴파일하여 캐싱**하는 기술로, Java(JVM)와 Python(PyPy) 등에서 사용됩니다.

### OS-061. 본인이 사용하는 언어는, 어떤식으로 컴파일 및 실행되는지 설명해 주세요.
(Python 기준) 소스 코드가 먼저 중간 언어인 **바이트코드(.pyc)**로 컴파일된 후, **PVM(Python Virtual Machine)**이라는 인터프리터가 이를 한 줄씩 기계어로 번역하여 실행합니다.

### OS-062. Python 같은 언어는 CPython, Jython, PyPy등의 다양한 구현체가 있습니다. 각각은 어떤 차이가 있을까요? 또한, 실행되는 과정 또한 다를까요?
기반이 되는 언어와 가상 머신이 다릅니다. **CPython**은 C언어 기반의 표준 인터프리터이고, **Jython**은 Java JVM 위에서 돌아가며, **PyPy**는 JIT 컴파일러를 탑재해 CPython보다 월등히 빠른 속도를 제공합니다.

### OS-063. 우리는 흔히 fork(), exec() 시스템 콜을 사용하여 프로세스를 적재할 수 있다고 배웠습니다. 로더의 역할은 이 시스템 콜과 상관있는 걸까요? 아니면 다른 방식으로 프로세스를 적재할 수 있는 건가요?
**`exec()` 시스템 콜이 호출될 때 커널 내부의 로더가 동작**합니다. 즉, `exec()`이 디스크에서 프로그램을 읽어와 현재 프로세스의 메모리를 덮어쓰는 과정 자체가 로더에 의해 수행됩니다.

## 11. IPC

### OS-064. IPC가 무엇이고, 어떤 종류가 있는지 설명해 주세요.
**IPC(Inter-Process Communication)**는 독립된 프로세스들끼리 데이터를 주고받기 위한 통신 메커니즘입니다. 대표적인 종류로는 **파이프(Pipe), 메시지 큐, 공유 메모리, 소켓(Socket)** 등이 있습니다.

### OS-065. Shared Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해 주세요.
프로세스 간에 **특정 메모리 영역을 물리적으로 공유**하여 데이터를 교환하는 가장 빠른 방식입니다. 하지만 여러 프로세스가 동시에 접근할 수 있으므로 **동기화(Synchronization) 문제**를 해결하지 않으면 데이터가 훼손될 수 있습니다.

### OS-066. 메시지 큐는 단방향이라고 할 수 있나요?
기본적으로는 단방향이지만, 설정을 통해 양방향으로 구현하거나 **수신용/송신용 큐를 2개** 만들어 양방향 통신을 수행할 수 있으므로 반드시 단방향이라고만은 할 수 없습니다.

## 12. 스레드 안전

### OS-067. Thread Safe 하다는 것은 어떤 의미인가요?
멀티 스레드 환경에서 여러 스레드가 동시에 공유 자원에 접근하더라도 **프로그램의 실행 결과가 올바르고 의도한 대로 동작함**을 보장하는 상태를 말합니다.

### OS-068. Thread Safe 를 보장하기 위해 어떤 방법을 사용할 수 있나요?
**뮤텍스(Mutex)** 등의 락(Lock)을 사용하여 상호 배제를 구현하거나, **스레드 로컬 스토리지(TLS)**를 사용해 자원 공유를 피하거나, 값을 변경할 수 없는 **불변 객체(Immutable Object)**를 사용하는 방법 등이 있습니다.

### OS-069. Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.
두 프로세스가 임계 구역에 들어갈 때 **flag와 turn 변수**를 사용해 상호 배제를 보장하는 소프트웨어 알고리즘입니다. 하지만 프로세스가 **단 2개일 때만 적용 가능**하며, 계속 루프를 도는 **Busy Waiting**으로 CPU를 낭비한다는 한계가 있습니다.

### OS-070. Race Condition 이 무엇인가요?
두 개 이상의 스레드나 프로세스가 공유 자원에 대해 동시에 읽거나 쓰려고 경쟁할 때, **접근 순서(타이밍)에 따라 실행 결과가 달라지는 상태**를 말합니다.

### OS-071. Thread Safe를 구현하기 위해 반드시 락을 사용해야 할까요? 그렇지 않다면, 어떤 다른 방법이 있을까요?
아니요, 락 없이도 **원자적 연산(Atomic Operation)**을 활용한 **Non-blocking(Lock-Free)** 알고리즘을 사용하거나, 전역 변수 대신 지역 변수만을 사용하는 **재진입성(Reentrancy) 코드**를 작성하면 됩니다.

## 13. Thread Pool, Monitor, Fork-Join

### OS-072. Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.
**스레드 풀**은 미리 생성한 스레드를 재활용하여 생성 비용을 아끼는 기법이고, **모니터**는 프로그래밍 언어 수준에서 제공하는 고수준 동기화 도구입니다. **Fork-Join**은 큰 작업을 작은 작업으로 쪼개어 병렬 처리한 뒤 결과를 합치는 프레임워크입니다.

### OS-073. Thread Pool을 사용한다고 가정하면, 어떤 기준으로 스레드의 수를 결정할 것인가요?
CPU 연산이 많은 작업(**CPU Bound**)이라면 불필요한 스위칭을 줄이기 위해 **코어 수 + 1** 정도로 설정하고, 대기 시간이 긴 작업(**I/O Bound**)이라면 코어 수보다 넉넉하게 설정하여 CPU 유휴 시간을 줄이는 것이 일반적입니다.

### OS-074. 어떤 데이터를 정렬 하려고 합니다. 어떤 방식의 전략을 사용하는 것이 가장 안전하면서도 좋은 성능을 낼 수 있을까요?
**병합 정렬(Merge Sort)** 전략을 사용하는 것이 좋습니다. 최악의 경우에도 $O(N \log N)$을 보장하며, 데이터를 독립적인 부분으로 나눌 수 있어 **Fork-Join 프레임워크를 이용한 병렬 정렬(Parallel Sort)**에 매우 적합하기 때문입니다.

## 14. 캐시 메모리

### OS-075. 캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.
**캐시 메모리**는 속도가 빠른 CPU와 상대적으로 느린 메인 메모리(RAM) 간의 속도 차이를 줄이기 위한 고속 버퍼 메모리입니다. 
**메모리 계층성**은 빠르고 비싼 메모리를 상위에, 느리고 저렴한 메모리를 하위에 배치하여 성능과 비용 효율을 최적화하는 구조입니다.

### OS-076. 캐시 메모리는 어디에 위치해 있나요?
과거에는 메인보드에 있었으나, 현대 시스템에서는 **CPU 코어 내부(L1, L2)**나 **CPU 다이(Die) 위(L3)**에 위치하여 CPU와 메모리 사이를 연결합니다.

### OS-077. L1, L2 캐시에 대해 설명해 주세요.
**L1 캐시**는 CPU 코어에 가장 가까워 속도가 가장 빠르며 명령어(Instruction)와 데이터(Data)용으로 분리되어 있고, **L2 캐시**는 L1보다 용량은 크지만 속도는 약간 느리며 주로 코어 전용 혹은 공유 형태로 사용됩니다.

### OS-078. 캐시에 올라오는 데이터는 어떻게 관리되나요?
데이터는 낱개가 아닌 **캐시 라인(Cache Line) 또는 블록 단위**로 묶여 관리됩니다. 캐시가 꽉 차면 LRU(Least Recently Used) 같은 교체 알고리즘에 따라 사용 빈도가 낮은 블록을 내보내고 새 데이터를 저장합니다.

### OS-079. 캐시간의 동기화는 어떻게 이루어지나요?
멀티 코어 환경에서는 **MESI 프로토콜** 등을 사용하며, 주로 **버스 스누핑(Bus Snooping)** 방식을 통해 한 코어가 데이터를 수정하면 다른 코어들의 캐시 내용을 무효화(Invalidate)하거나 업데이트하여 일관성을 유지합니다.

### OS-080. 캐시 메모리의 Mapping 방식에 대해 설명해 주세요.
주소를 단순하게 매칭하는 **직접 매핑(Direct Mapping)**, 빈 공간 어디든 넣는 **연관 매핑(Associative Mapping)**, 그리고 이 둘을 합쳐 검색 속도와 저장 효율을 절충한 **집합 연관 매핑(Set Associative Mapping)** 방식이 있습니다. 

### OS-081. 캐시의 지역성에 대해 설명해 주세요.
한번 참조된 데이터는 다시 참조될 가능성이 높은 **시간 지역성(Temporal Locality)**과, 참조된 데이터의 주변 데이터가 참조될 가능성이 높은 **공간 지역성(Spatial Locality)**을 의미합니다.

### OS-082. 캐시의 지역성을 기반으로, 이차원 배열을 가로/세로로 탐색했을 때의 성능 차이에 대해 설명해 주세요.
C언어 등 행 우선(Row-major) 저장 방식 언어에서는 **가로(행) 방향**으로 탐색할 때 메모리 주소가 연속적이므로 **공간 지역성**에 의해 캐시 적중률(Hit rate)이 높아 성능이 월등히 좋습니다. 

### OS-083. 캐시의 공간 지역성은 어떻게 구현될 수 있을까요? (힌트: 캐시는 어떤 단위로 저장되고 관리될까요?)
캐시가 메모리에서 데이터를 가져올 때, 요청된 바이트 하나만 가져오는 것이 아니라 그 인접한 데이터 묶음인 **블록(Block) 혹은 캐시 라인(Cache Line)** 단위(보통 64Bytes)로 한꺼번에 가져옴으로써 구현됩니다.

## 14-1. 캐시 메모리 꼬리질문 - 캐시 일관성 (Cache Coherency)

### 꼬리질문1. 멀티 코어 환경에서 '캐시 일관성 문제'란 정확히 무엇인가요?
각 코어가 독립된 L1/L2 캐시를 가지고 있기 때문에, 코어 A가 공유 변수 값을 변경했을 때 코어 B의 캐시에는 여전히 **변경 전의 옛날 값(Stale Data)**이 남아있어 데이터 불일치가 발생하는 현상입니다.

### 꼬리질문2. 운영체제나 하드웨어는 이 문제를 어떻게 해결하나요? (버스 스누핑)
주로 **버스 스누핑(Bus Snooping)** 방식을 사용합니다. 모든 캐시 컨트롤러가 버스(데이터 통로)를 항상 감시(Snoop)하고 있다가, 다른 코어가 특정 주소의 데이터를 변경한다는 신호를 보내면 자신의 캐시에 있는 해당 데이터를 **무효화(Invalidate)**시켜 일관성을 맞춥니다.

### 꼬리질문3. 이와 관련된 'MESI 프로토콜'에 대해 들어보셨나요?
캐시 라인의 상태를 4가지(**M**odified, **E**xclusive, **S**hared, **I**nvalid)로 정의하여 관리하는 프로토콜입니다. 데이터가 수정되었는지, 공유 중인지, 무효한지 상태 비트를 두어 일관성을 효율적으로 유지합니다.

### 꼬리질문4. '거짓 공유(False Sharing)' 문제로 성능이 저하될 수 있다던데, 무엇인가요?
실제로는 서로 다른 변수(`A`, `B`)를 사용하지만, 운 나쁘게 **같은 캐시 라인(블록)**에 저장되어 있을 때 발생합니다. 한 코어가 `A`만 수정해도 `B`까지 포함된 전체 캐시 라인이 무효화되므로, 불필요한 버스 트래픽이 발생해 성능이 급격히 떨어집니다.

## 15. 메모리 할당 기법

### OS-084. 연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)
**First-fit**은 들어갈 수 있는 첫 번째 공간에 할당하여 가장 빠르고, **Best-fit**은 남는 공간이 가장 적은 곳에 할당하여 공간 효율을 높이며, **Worst-fit**은 가장 큰 공간에 할당하여 남은 공간을 크게 만드는 방식입니다.

### OS-085. worst-fit 은 언제 사용할 수 있을까요?
할당 후 남은 공간(자투리)이 너무 작아 아무도 쓸 수 없는 **외부 단편화 문제를 줄이고**, 남은 공간을 일부러 크게 만들어 다른 프로세스가 활용할 수 있게 하려 할 때 유용합니다.

### OS-086. 성능이 가장 좋은 알고리즘은 무엇일까요?
일반적으로 검색 속도가 빠른 **First-fit**이 시간 성능 면에서 가장 우수하고, 공간 효율 면에서는 Best-fit이 좋다고 평가받지만, 시스템 환경에 따라 다릅니다.

## 16. Thrashing

### OS-087. Thrashing 이란 무엇인가요?
동시에 실행되는 프로세스가 너무 많아 메모리가 부족해지면서, CPU가 실제 작업보다 **페이지를 교체(Swapping)하는 데 대부분의 시간을 소비**하여 성능이 급격히 떨어지는 현상입니다.

### OS-088. Thrashing 발생 시, 어떻게 완화할 수 있을까요?
**다중 프로그래밍의 정도(Degree of Multiprogramming)를 낮춰** 실행 중인 프로세스 일부를 중단시키거나, **워킹 셋(Working Set) 모델**을 사용하여 각 프로세스가 필요로 하는 최소한의 프레임 수를 보장해주어야 합니다.

## 17. 가상 메모리

### OS-089. 가상 메모리란 무엇인가요?
물리 메모리(RAM)의 크기에 구애받지 않고, 프로세스에게 **커다란 연속적인 메모리 공간을 가지고 있다는 환상**을 제공하는 메모리 관리 기술입니다.

### OS-090. 가상 메모리가 가능한 이유가 무엇일까요?
프로그램 실행 시 **모든 코드가 동시에 필요하지 않다는 점(지역성)**과, 당장 필요한 부분만 메모리에 올리는 **요구 페이징(Demand Paging)** 기술 덕분입니다.

### OS-091. Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.
CPU가 운영체제에 트랩(Trap)을 보내면, 운영체제는 디스크(Swap Area)에서 해당 페이지를 찾아 빈 물리 프레임에 적재하고 페이지 테이블을 업데이트한 뒤, 중단됐던 명령어를 재실행합니다.

### OS-092. 페이지 크기에 대한 Trade-Off를 설명해 주세요.
페이지가 **작으면** 내부 단편화는 줄지만 페이지 테이블 크기가 커져 오버헤드가 발생하고, **크면** 테이블 크기는 줄지만 내부 단편화가 커지고 불필요한 데이터까지 로딩될 수 있습니다.

### OS-093. 페이지 크기가 커지면, 페이지 폴트가 더 많이 발생한다고 할 수 있나요?
일반적으로는 페이지가 클수록 한 번에 많은 데이터를 가져오므로(공간 지역성) **페이지 폴트 횟수 자체는 줄어듭니다.** 다만, 너무 크면 불필요한 데이터가 메모리를 차지해 꼭 필요한 정보가 밀려나는 경우도 생길 수 있습니다.

### OS-094. 세그멘테이션 방식을 사용하고 있다면, 가상 메모리를 사용할 수 없을까요?
아니요, 사용할 수 있습니다. 세그멘테이션 단위로 필요한 부분만 메모리에 올리고 내리는 방식(Swapping)으로 가상 메모리를 구현할 수 있습니다.

## 18. 세그멘테이션 & 페이징

### OS-095. 세그멘테이션과 페이징의 차이점은 무엇인가요?
**페이징**은 물리적 효율을 위해 고정된 크기(Page)로 자르는 방식이고, **세그멘테이션**은 논리적 의미(함수, 스택 등)를 기준으로 가변적인 크기로 자르는 방식입니다.

### OS-096. 페이지와 프레임의 차이에 대해 설명해 주세요.
둘은 크기가 같지만, **페이지**는 가상 메모리 상의 논리적인 블록이고, **프레임**은 실제 물리 메모리(RAM) 상의 물리적인 블록을 의미합니다.

### OS-097. 내부 단편화와, 외부 단편화에 대해 설명해 주세요.
**내부 단편화**는 할당된 공간(Page)이 실제 데이터보다 커서 내부 공간이 남는 것이고(페이징), **외부 단편화**는 남은 공간의 총량은 충분하나 조각조각 흩어져 있어 할당할 수 없는 것(세그멘테이션)입니다.

### OS-098. 페이지에서 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.
가상 주소를 **페이지 번호(p)와 오프셋(d)**으로 나눈 뒤, 페이지 테이블에서 해당 페이지 번호에 매핑된 **프레임 번호(f)**를 찾아 오프셋과 합쳐 물리 주소를 완성합니다.

### OS-099. 어떤 주소공간이 있을 때, 이 공간이 수정 가능한지 확인할 수 있는 방법이 있나요?
페이지 테이블 항목(PTE)에는 주소 정보뿐만 아니라 **보호 비트(Protection Bit)**가 있어, 해당 페이지에 대한 읽기/쓰기/실행 권한(R/W/X)을 하드웨어가 확인합니다.

### OS-100. 32비트에서, 페이지의 크기가 1kb 이라면 페이지 테이블의 최대 크기는 몇 개일까요?
32비트 주소 공간($2^{32}$)을 1KB($2^{10}$) 단위로 나누면 되므로, 페이지 테이블 항목(Entry)의 개수는 $2^{32} / 2^{10} = 2^{22}$, 즉 약 **400만 개(4M)**가 됩니다.

### OS-101. 32비트 운영체제는 램을 최대 4G 까지 사용할 수 있습니다. 이 이유를 페이징과 연관 지어서 설명해 주세요.
32비트 레지스터가 표현할 수 있는 고유한 주소의 개수가 $2^{32}$개(약 42억)이므로, 논리적으로 가리킬 수 있는 메모리 주소의 최대 한계가 **4GB**이기 때문입니다.

### OS-102. C/C++ 개발 시 Segmentation Fault 에러는 세그멘테이션/페이징과 어떤 관계가 있을까요?
과거 세그멘테이션 보호 기법에서 유래된 용어지만, 현대에는 페이징 시스템에서 **허용되지 않은 메모리 주소에 접근하거나 권한(Read-only 등)을 위반했을 때** 발생하는 범용적인 메모리 접근 오류를 뜻합니다.

### 18-1. 세그멘테이션 & 페이징 - 페이징과 세그멘테이션의 차이

### 꼬리질문1. 페이징과 세그멘테이션의 가장 큰 차이점은 무엇인가요?
메모리를 나누는 **기준(Unit)**이 다릅니다. **페이징**은 크기가 **고정된(Fixed) 블록(Page)**으로 무조건 균일하게 자르는 방식이고, **세그멘테이션**은 코드, 데이터, 스택 등 **논리적 의미 단위(Logical Unit)**에 따라 **가변적인 크기**로 자르는 방식입니다.

### 꼬리질문2. 각각 어떤 단편화(Fragmentation) 문제가 발생하나요?
**페이징**은 마지막 페이지가 꽉 차지 않을 때 낭비되는 공간인 **내부 단편화(Internal Fragmentation)**가 발생합니다. 반면 **세그멘테이션**은 서로 다른 크기의 조각들이 할당/해제되면서 중간중간에 너무 작은 빈 공간이 생기는 **외부 단편화(External Fragmentation)**가 발생합니다.

### 꼬리질문3. 세그멘테이션 테이블에는 페이징 테이블에 없는 특별한 값이 있다던데 무엇인가요?
바로 **Limit(길이/크기) 정보**입니다. 페이징은 크기가 일정해서 시작 주소만 알면 되지만, 세그멘테이션은 크기가 제각각이므로 **시작 주소(Base)**와 더불어 **해당 세그먼트의 끝(Limit)**을 기록해 두어야 메모리 침범 오류를 막을 수 있습니다.

### 꼬리질문4. 그렇다면 현대 운영체제는 이 두 가지 중 어떤 방식을 사용하나요?
두 방식의 장점을 합친 **Paged Segmentation(세그먼트 된 페이징)** 기법을 사용합니다. 프로그램을 의미 단위인 세그먼트로 나누되, 각 세그먼트를 다시 고정 크기의 페이지로 잘라서 메모리에 할당함으로써 **외부 단편화 문제를 해결**하고 보호(Protection) 기능도 유지합니다.

## 19. TLB

### OS-103. TLB는 무엇인가요?
**Translation Lookaside Buffer**의 약자로, 가상 주소를 물리 주소로 변환하는 속도를 높이기 위해 페이지 테이블의 변환 정보를 저장하는 **특수한 고속 하드웨어 캐시**입니다.

### OS-104. TLB를 쓰면 왜 빨라지나요?
주소 변환을 위해 매번 메인 메모리에 있는 페이지 테이블에 접근하는 오버헤드를 줄이고, **캐시에서 즉시 물리 주소를 얻어올 수 있기 때문**입니다.

### OS-105. MMU가 무엇인가요?
**Memory Management Unit**의 약자로, CPU가 메모리에 접근할 때 가상 주소를 실제 물리 주소로 변환하고 메모리 보호 기능을 수행하는 **핵심 하드웨어 장치**입니다.

### OS-106. TLB와 MMU는 어디에 위치해 있나요?
빠른 데이터 접근과 변환 처리를 위해 **CPU 코어 내부(혹은 프로세서 칩 내)**에 위치해 있습니다.

### OS-107. 코어가 여러개라면, TLB는 어떻게 동기화 할 수 있을까요?
하나의 코어에서 페이지 매핑이 변경되면, **TLB Shootdown**이라는 작업을 통해 다른 코어들에게 인터럽트를 보내 해당 TLB 항목을 무효화(Invalidate)하도록 강제합니다.

### OS-108. TLB 관점에서, Context Switching 발생 시 어떤 변화가 발생하는지 설명해 주세요.
프로세스가 바뀌면 가상 주소 매핑 정보도 완전히 달라지므로, 기존 **TLB 내용을 모두 비우거나(Flush)**, ASID(Address Space ID)를 사용해 현재 프로세스의 항목만 유효한 것으로 식별해야 합니다.

## 20. 동기화 구현

### OS-109. 동기화를 구현하기 위한 하드웨어적인 해결 방법에 대해 설명해 주세요.
하드웨어 차원에서 더 이상 쪼갤 수 없는 **원자적 명령어(Atomic Instruction)**인 `Test-and-Set`이나 `Compare-and-Swap(CAS)` 등을 제공하여 읽기와 쓰기가 한 번에 실행됨을 보장합니다.

### OS-110. volatile 키워드는 어떤 의미가 있나요?
컴파일러에게 **"이 변수는 외부(다른 스레드/하드웨어)에 의해 언제든 값이 바뀔 수 있으니 최적화(레지스터 캐싱)하지 말고 항상 메모리에서 직접 읽으라"**고 지시하는 키워드입니다.

### OS-111. 싱글코어가 아니라 멀티코어라면, 어떻게 동기화가 이뤄질까요?
원자적 명령어를 수행할 때 시스템 버스(Bus)에 시그널을 보내 다른 코어의 접근을 막는 **버스 잠금(Bus Lock)**이나, 캐시 일관성 프로토콜을 활용한 **캐시 잠금**을 통해 동기화를 수행합니다.

## 21. 페이징 알고리즘

### OS-112. 페이지 교체 알고리즘에 대해 설명해 주세요.
물리 메모리가 가득 찼을 때, 새로운 페이지를 적재하기 위해 **기존 페이지 중 어떤 것을 디스크로 내보낼지(Swap-out) 결정하는 정책**입니다. 페이지 부재(Page Fault) 발생 빈도를 최소화하여 시스템 성능을 유지하는 것이 목적입니다.

### OS-113. LRU 알고리즘은 어떤 특성을 이용한 알고리즘이라고 할 수 있을까요?
"최근에 사용되지 않은 페이지는 앞으로도 사용될 확률이 낮다"는 **시간 지역성(Temporal Locality)** 원리를 이용합니다. 즉, 가장 오랫동안 참조되지 않은 페이지를 교체 대상(Victim)으로 선정합니다.

### OS-114. LRU 알고리즘을 구현한다면, 어떻게 구현할 수 있을까요?
주로 **이중 연결 리스트(Doubly Linked List)**로 순서를 관리하고 **해시 맵(Hash Map)**으로 위치를 저장하여 구현합니다. 페이지에 접근할 때마다 해당 노드를 리스트의 가장 앞으로 옮기는 방식(접근 $O(1)$)을 사용합니다.

### OS-115. LRU 알고리즘의 단점을 설명해 주세요. 이를 해결할 수 있는 대안에 대해서도 설명해 주세요.
모든 접근마다 시간을 기록하거나 순서를 변경해야 하므로 **오버헤드가 크고**, 순환적인 패턴(Loop)으로 데이터를 읽을 때 성능이 떨어지는 단점이 있습니다. 이를 보완하기 위해 참조 횟수를 고려하는 **LFU**나, 하드웨어 비트를 활용해 오버헤드를 줄인 **Clock 알고리즘(NUR)**이 대안으로 사용됩니다.

## 21-1. 페이징 알고리즘 꼬리질문 - Clock 알고리즘

### 꼬리질문1. Clock 알고리즘이 무엇인가요?
LRU 알고리즘은 구현 비용이 비싸기 때문에, 이를 **하드웨어적인 지원(참조 비트)**을 통해 적은 오버헤드로 흉내 낸 **LRU의 근사(Approximation) 알고리즘**입니다. 페이지들을 원형 큐처럼 배치하고 시계 바늘처럼 순회한다고 하여 Clock 알고리즘이라 부릅니다.

### 꼬리질문2. 구체적으로 어떻게 교체 대상을 찾나요?
시계 바늘(포인터)이 페이지를 가리킬 때, **참조 비트(Reference Bit)**가 1이면 0으로 바꾸고 다음으로 넘어갑니다. 만약 참조 비트가 0인 페이지를 만나면 그 페이지를 교체 대상(Victim)으로 선정합니다.

### 꼬리질문3. 왜 이를 '2차 기회(Second Chance) 알고리즘'이라고도 부르나요?
최근에 참조된 페이지(비트가 1인 경우)를 바로 쫓아내지 않고, **비트를 0으로 초기화한 뒤 한 바퀴를 더 돌 수 있는 기회(Second Chance)**를 주기 때문입니다. 즉, "방금 썼으니 한 번 봐준다"는 개념입니다.

### 꼬리질문4. LRU 대신 Clock 알고리즘을 쓰는 이유는 무엇인가요?
LRU는 매번 리스트의 순서를 변경해야 해서 오버헤드가 크지만, Clock 알고리즘은 **단순히 비트 하나만 확인하고 수정**하면 되므로 훨씬 빠르고 시스템 부담이 적기 때문입니다.

# 22. 파일 시스템 및 I/O

### OS-116. File Descriptor와, File System에 대해 설명해 주세요.
**파일 디스크립터(FD)**는 운영체제가 특정 프로세스에서 열려 있는 파일이나 소켓을 식별하기 위해 부여하는 음이 아닌 정수값(Index)입니다. **파일 시스템**은 저장 장치 내에서 데이터를 파일 단위로 저장, 검색, 관리하기 위해 정의된 논리적인 구조이자 체계입니다.

### OS-117. I-Node가 무엇인가요?
**I-Node(Index Node)**는 유닉스 계열 파일 시스템에서 사용하는 자료구조로, 파일의 이름과 실제 내용을 제외한 **모든 메타데이터(파일 크기, 권한, 소유자, 실제 데이터 블록의 위치 등)**를 저장하고 있습니다.

### OS-118. 프로그래밍 언어 상에서 제공하는 파일 관련 함수는, 파일을 어떤 방식으로 읽어들이나요?
표준 라이브러리 함수가 내부적으로 **시스템 콜(`open`, `read`)**을 호출하여 커널에 요청을 전달하는 방식으로 동작합니다. 이때, 매번 시스템 콜을 호출하는 오버헤드를 줄이기 위해 언어 차원에서 **버퍼(Buffer)**를 두어 데이터를 모아서 처리하는 경우가 많습니다.

# 23. 동기 & 비동기

### OS-119. 동기와 비동기, 블로킹과 논블로킹의 차이에 대해 설명해 주세요.
**동기/비동기**는 작업 완료 여부를 누가 신경 쓰는지(순서 보장)에 대한 **타이밍**의 관점이고, **블로킹/논블로킹**은 호출된 함수가 제어권(Return)을 바로 돌려주는지에 대한 **제어 흐름**의 관점입니다.

### OS-120. 그렇다면, 동기이면서 논블로킹이고, 비동기이면서 블로킹인 경우는 의미가 있다고 할 수 있나요?
**동기+논블로킹**은 작업 완료를 계속 확인하는 **폴링(Polling)** 방식으로서 의미가 있지만, **비동기+블로킹**은 비동기의 이점(병렬성)을 버리고 대기하므로 실무적으로는 **안티 패턴**이거나 특수한 경우(MySQL 드라이버 등)를 제외하면 비효율적입니다.

### OS-121. I/O 멀티플렉싱에 대해 설명해 주세요.
하나의 프로세스나 스레드가 **여러 개의 파일 디스크립터(Socket 등)를 관찰**하고 있다가, 입출력이 준비된(Ready) 대상이 생기면 해당 작업을 처리하는 기술(select, poll, epoll 등)입니다.

### OS-122. 논블로킹 I/O를 수행한다고 하면, 그 결과를 어떻게 수신할 수 있나요?
작업 요청 시 즉시 제어권을 돌려받기 때문에, 이후 **주기적으로 완료 여부를 확인(Polling)**하거나, **I/O 멀티플렉싱(epoll 등)**을 통해 데이터가 준비되었다는 알림을 받아 결과를 수신합니다.

## 23-1. 동기 & 비동기 꼬리질문 - I/O 멀티플렉싱의 구현 방식과 Redis의 성능 비결

### 꼬리질문1. Select, Poll, Epoll의 차이점에 대해 설명해 주세요.
* **Select:** 관리할 수 있는 소켓 개수에 제한(기본 1024개)이 있고, 데이터가 들어왔는지 확인하기 위해 **매번 전체 목록을 순회($O(N)$)**해야 하므로 비효율적입니다.
* **Poll:** Linked List를 사용하여 개수 제한은 해결했지만, 여전히 **전체 목록을 검사($O(N)$)**해야 하는 성능 문제는 남아있습니다.
* **Epoll:** **이벤트가 발생한 소켓만 추려내어 처리($O(1)$)**하므로, 접속자가 아무리 많아도 성능 저하가 거의 없는 리눅스 환경의 가장 최신 방식입니다.

| 구분 | Select | Poll | Epoll |
| :--- | :--- | :--- | :--- |
| **복잡도** | $O(N)$ (전체 검사) | $O(N)$ (전체 검사) | $O(1)$ (이벤트 발생만) |
| **개수 제한** | 있음 (FD_SETSIZE) | 없음 | 없음 |
| **특징** | 호환성 좋음, 느림 | Select와 유사, 제한 없음 | **대용량 처리에 최적** |

### 꼬리질문2. Redis는 싱글 스레드인데 왜 성능이 빠른가요?

**I/O 멀티플렉싱(Epoll/Kqueue)** 기술을 사용하여 하나의 스레드로도 I/O 대기 없이 여러 요청을 동시에 처리할 수 있기 때문입니다. 또한, 멀티 스레드에서 발생하는 **문맥 교환(Context Switch) 비용**과 **자원 경쟁(Lock) 문제**가 없어 CPU 효율이 극대화됩니다.
