# Operating System (운영체제)

## 📌 시스템 콜

### OS-001
Q. 시스템 콜이 무엇인지 설명해 주세요.

운영체제의, 다시말해 커널의 기능을 사용하기 위한 공식적인 요청. 하드웨어 자원을 직접 관리하는 커널과 독립되어, 필요한 기능이 있을때마다 호출이 되어 커널에게 요청하는 인터페이스를 시스템 콜이라고 함.

### OS-002
Q. 우리가 사용하는 시스템 콜의 예시를 들어주세요.

- File Management
    - `open()`: 파일을 열거나, 파일이 없으면 생성
    - `read()`: 파일에서 데이터를 읽음
    - `write()`: 파일에서 데이터를 씀
    - `close()`: 사용이 끝난 파일을 종료
    - `unlink()`: 파일을 삭제

- Process Management
    - `fork()`: 현재 프로세스와 동일한 프로세스를 생성
    - `exec()`: 현재 프로세스에 새로운 프로그램을 덮어씌워 실행
    - `exit()`: 프로세스를 종료
    - `wait()`: 자식 프로세스가 끝날때까지 기다림

### OS-003
Q. 시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.

1. [유저모드] 함수호출: 유저프로그램이 함수를 호출.
2. [유저모드] 시스템콜 번호 준비: ex) `read()`함수는 "파일 읽기"에 해당하는 시스템 콜 번호를 CPU의 특정 저장 공간(레지스터)에 저장. (전달할 데이터 (버퍼 주소)도 레지스터에 저장)
3. [유저모드] SYSCALL 실행: SYSCALL 실행 -> 소프트웨어 인터럽트 발생
4. [커널모드] 
    - SYSCALL을 받은 커널은 즉시 유저모드를 멈추고, 커널모드로 전환
    - 커널은 약속된 시스템 콜 테이블을 확인하여 시스템 콜 핸들러를 찾아냄
5. [커널모드]
    - 실제로 커널 코드를 실행
6. [커널모드] 결과 반환 (유저프로그램이 확인가능한 공간에 결과 저장) 및 유저모드로 모드를 복귀
7. [유저모드] 작업 복귀


### OS-004
Q. 시스템 콜의 유형에 대해 설명해 주세요.

1. Process Control
2. File Management
3. Device Management
4. Communication
    - 프로세스간 통신 (ipc)를 위한 연결(pipe, socket)
    - 공유메모리 (shmget)을 생성하여 프로세스가 데이터를 공유

### OS-005
Q. 운영체제의 Dual Mode 에 대해 설명해 주세요.

CPU가 명령어를 실행할 때, 커널이 실행하는지, 사용자 프로그램이 실행하는지 구분하는 하드웨어 보호기법. 
- ModeBit를 통해 구분:
    - 0 (커널모드): Priviliged Instruction 실행 가능.
    - 1 (유저모드)

### OS-006
Q. 왜 유저모드와 커널모드를 구분해야 하나요?

시스템의 안정성과 보호를 위해서 구분해야함.

### OS-007
Q. 서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?

커널은 System Call Number를 사용하여 여러 개의 서로 다른 시스템 콜을 구분

---

## 📌 인터럽트

### OS-008
Q. 인터럽트가 무엇인지 설명해 주세요.

CPU가 프로그램을 실행하고 있을때, 예외 상황이나 입출력 장치의 이벤트가 발생하여 현재 작업을 즉시 멈추고 해당 처리를 먼저 하도록 보내는 신호

### OS-009
Q. 인터럽트는 어떻게 처리하나요?

'중단' -> '처리' -> '저장' -> '복구'

1. 요청 대기 및 중단: CPU는 매 명령어 실행이 끝날때마다 인터럽트 신호를 확인. 신호를 받게 되면 실행중인 프로세스나 쓰레드를 중지
2. Context 저장: 나중에 다시 돌아오기 위해 PC와 Register 값 등의 메타 데이터를 스택이나 PCB에 저장.
3. 핸들러 탐색: Interrupt Descriptor Table을 탐색 -> 해당 표에는 각 Interrupt Number 마다 Interrupt Service Routine이 저장 되어 있음.
4. ISR 실행: 알아낸 주소로 점프하여 실제 처리코드를 커널모드에서 실행.
5. Context 복구: `IRET`명령어를 사용하여 저장해둔 PC와 레지스터 값을 복구.

### OS-010
Q. Polling 방식에 대해 설명해 주세요.

Active Checking을 통해, CPU가 입출력 장치의 상태를 주기적으로 검사. 이로인해 CPU가 의미 없는 코드를 실해앟여 리소스를 낭비하는 busy waiting이 발생

### OS-011
Q. HW / SW 인터럽트에 대해 설명해 주세요.

HW Interrupt: CPU 외부의 장치가 발생 -> 비동기적으로 발생
SW Interrupt: 실행중인 프로그램이 코드를 실행하던 도중 발생 -> 동기적으로 발생 / ex) Exception, Systemcall

### OS-012
Q. 동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?

1. Priority에 따른 Nested Interrupt: 우선순위에 따라 처리. 현재 처리중인 interrupt 보다 우선순위가 높은 interrupt가 발생한 경우, 현재 처리중인 interrupt를 중단하고 상위 interrupt를 처리.
2. 순차처리: interrupt 발생 순서에 따라 처리. 한 interrupt를 처리하는 동안 다른 interrupt가 발생하더라도 다른 interrupt를 무시하거나 대기시킴.

---

## 📌 프로세스

### OS-013
Q. 프로세스가 무엇인가요?

메모리에 적재되어 실행중인 프로그램 (Program in Execution). Static한 상태의 Program이 메모리에 로드되어 CPU를 할당 받아 명령을 수행하는, Active한 상태. 자원의 할당 단위이며, 총 4개의, `Code, Data, Heap, Stack`의 독립적인 메모리 영역을 가짐.

### OS-014
Q. 프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.

프로세스는 운영체제로부터 자원을 할당 받는 최소의 단위이며, 스레드는 프로세스의 자원 (`Code, Data, Heap`)을 공유하면서, 별도의 `Stack`과 Program Counter만 가지고 CPU를 점유하는, 실질적인 실행의 단위

### OS-015
Q. PCB가 무엇인가요?

커널이 프로세스를 제어하고 관리하기 위해 프로세스에 대한 정보를 저장해 두는 자료구조.
** 주요 저장 자료구조:
- PID
- 프로세스 상태
- Program Counter
- CPU Register 값
- 메모리 관리 정보

### OS-016
Q. 그렇다면, 스레드는 PCB를 갖고 있을까요?

PCB와 유사한 TCB를 가지고 있음
** 주요 저장 정보:
- Stack Pointer
- Program Counter
- 레지스터 값

### OS-017
Q. 리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?

프로세스: `fork()`
- 부모 프로세스를 그대로 복제하여 새로운 프로세스를 만듦.
- 메모리 공간을 별도로 Copy-on-Write하여 독립적인 공간을 가짐

스레드: `clone` or `pthred_create()`
- `clone()`에 `CLONE_VM`, `CLONE_FS`와 같은 플래그를 포함시켜 부모와 자원을 공유하도록 함.

### OS-018
Q. 자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?

1. Zombie Process
- 자식 프로세스가 exit() 되었지만, 부모프로세스가 아직 wait() 시스템콜을 호출하여 자식의 종료상태를 회수하지 않은 상태
- 자식은 이미 kill되어 메모리는 해제 되었지만, 프로세스 테이블에는 PID와 종료상태가 남아있음.

2. Orphan Process
- 자식은 아직 실행 중인데, 부모 프로세스가 먼저 종료된 상황
- 새로운 init Process가 새로운 부모(PID=1)가 되어줌.

### OS-019
Q. 리눅스에서, 데몬프로세스에 대해 설명해 주세요.

사용자와 직접 상호작용하지 않고, 백그라운드에서 실행되며 특정 서비스를 제공하는 프로세스

### OS-020
Q. 리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.

`init` or `systemd` 프로세스; PID가 1번

---

## 📌 프로세스 주소공간

### OS-021
Q. 프로세스 주소공간에 대해 설명해 주세요.

총 4가지 영역으로 구분됨, 
1) Code: 실행할 프로그램의 명령어 집합
2) Data: 전역변수와 지역변수가 저장. 프로그램 시작시 할당되고 소멸
3) Heap: 프로그래머가 필요에 의해 동적으로 할당. 낮은 주소 -> 높은 주소
4) Stack: 함수 호출시 생성되는 지역변수, 매개변수, 리턴주소가 저장. 높은 주소 -> 낮은 주소

### OS-022
Q. 초기화 하지 않은 변수들은 어디에 저장될까요?

BSS (Block Started by Symbol)영역에 저장

### OS-023
Q. 일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?

프로그램 실행시, runtime상에 결정.

### OS-024
Q. Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?

Stack. Allocation mechanism 상, stack pointer를 단순히 이동시키기만 하면 됨. 또한, 연속된 공간 상에 저장이 되므로 Spatial Locality가 높아 CPU 캐시 Hitrate가 높음.

### OS-025
Q. 다음과 같이 공간을 분할하는 이유가 있을까요?

1. 데이터의 성격에 따른 공간 효율성:
    - 같은 프로그램을 여러 개 실행할 경우, `Code`영역은 모두 동일하므로 모든 프로세스가 이를 공유하면 자원을 효율적으로 사용할 수 있음.
2. 보호 및 안정성:
    - 각 영역마다 권한 설정이 다름
        - `Code` -> Read Only
        - `Stack/Data` -> Read-Write

### OS-026
Q. 스레드의 주소공간은 어떻게 구성되어 있을까요?

상기 작성한 답변 참고.

### OS-027
Q. "스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.

- 스택의 경우, 자료구조 상의 스택과 유사하게 프레임이 LIFO 대로 처리됨.
- But, 힙의 경우는 ,자료구조 상의 힙과는 무관하게, 빈 메모리 공간으로서 작용. 최댓값이나 최솟값을 빠르게 찾기 위한 트리기반의 구조가 아님.

### OS-028
Q. IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요?

Heap과 Stack사이에 존재하는 Memory Mapping Segment. 주로 mmap()이라는 시스템 콜을 통해 별도의 공간에 매핑

### OS-029
Q. 스택과 힙영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요?

Heap -> 런타임 상에 결정. Stack -> 프로세스가 생성될 때 최대 limit이 결정. 리눅스 상에서 ulimit이라는 시스템 콜을 통해 결정 가능
---

## 📌 CPU 스케줄링

### OS-030
Q. 단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.

1. 장기 (Long-term Scheduler / Job Scheduler)
- 하드디스크에 있는 프로그램을 메모리 (Ready Queue)로 적재할지 결정
- 시스템 전체의 프로그램 수 (Degree of Multiprogramming)을 결정

2. 중기 (Medium-term Scheduler / Swapper)
- 메모리가 부족하면 프로세스를 통째로 디스크로 쫓아내고, 공간이 생기면 다시 불러들임.

3. 단기 (Short-tem Scheduler / CPU Scheduler)
- 메모리에 있는 ready 상태의 process중 하나를 불러와 CPU를 할당.

### OS-031
Q. 현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?

아니다. 장기 스케줄러는 거의 사용하지 않음. 메모리 공간이 여유로워졌기에 대부분의 프로그램을 메모리에 올림. 프로세스의 수를 사용자가 결정하게 됨.

### OS-032
Q. 프로세스의 스케쥴링 상태에 대해 설명해 주세요.

1) New: 프로세스가 막 생성되어 메모리에 로드되기 전 또는 막 로드 된 상태.
2) Ready: CPU를 얻기 위해 메모리에서 대기하는 상태
3) Running: CPU를 할당받아 실제 명령어를 수행중인 상태
4) Waiting/Blocked: I/O작업 등으로 인해 인터럽트가 발생하여 대기중인 상태
5) Terminated: 실행이 끝나고 종료된 상태

### OS-033
Q. preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?

non-preemptive 방식에서는 running -> ready로 가는 상태변화가 존재하지 않음.

### OS-034
Q. Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?

Swapper에 의해 Swap Out되어 Suspended 처리됨.
- Suspended Ready: ready 상태에서 swap out
- Suspended Wait: waiting/blocked 상태에서 swap out

---

## 📌 컨텍스트 스위칭

### OS-035
Q. 컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?

1. program counter 및 stack pointer 등의 현재 프로세스의 값들을 PCB 상에 저장.
2. PCB의 상태를 ready 또는 waiting/blocked로 변경
3. 다음 프로세스 선택
4. 다음 프로세스 복구

### OS-036
Q. 프로세스와 스레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?

1. Save/Restore시 필요한 정보의 양 차이
- 프로세스; PCB, 레지스터 메모리 맵 등을 저장해야함.
- 스레드; TCB내 Stack Pointer와 PC, 레지스터만 교체하면 됨.

2. 캐시 적중률
- 프로세스: 주소공간이 아예 바뀌므로, CPU 내의 TLB(주소변환캐시)를 초기화 해야함. -> 속도가 현격히 느림.
- 스레드: 메모리 공간을 공유하기에 TLB와 캐시를 비울 필요가 없음. 스위칭 후에도 캐시히트율이 유지됨.

### OS-037
Q. 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?

트랩 프레임의 형태로 저장.

### OS-038
Q. 컨텍스트 스위칭은 언제 일어날까요?

- I/O 요청
- Time Quantum 만료
- 인터럽트 처리
- 프로세스 종료
---

## 📌 스케줄링 알고리즘

### OS-039
Q. 프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?

1. Preemptive
    - First Come First Served
    - Shortest Job First
2. Non-preemptive
    - Round Robin
    - Shortest Remaining Job First
    - Priority Scheduling
    - Multi-Level Feedback Queue

### OS-040
Q. RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.

타임슬라이스가 작다면, 컨텍스트 스위칭이 불필요하게 빈번하게 발생. 만약 타임 슬라이스가 크다면, FCFS와 동일

### OS-041
Q.  스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요?

Priority Scheduling을 선택. 다른 프로세스에 비해 높은 우선순위를 부여하여, CPU를 계속 점유할 수 있도록 장려. 상시 가동되기에 context switching이 적게 발생하도록 함이 경제적.

### OS-042
Q. 동시성과 병렬성의 차이에 대해 설명해 주세요.

동시성: 싱글 CPU가 작업을 여러개로 쪼개어 번갈아 가며 시행. 실제로는 동시에 실행되는 것은 아니지만 동시에 실행되는 것처럼 보임.
병렬성: 멀티코어 CPU 상에서 실제로 2개 이상의 코어가 각자 다른 작업을 같은 시각에 수행.

### OS-043
Q. 타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?

이론상 Shortest Job First 알고리즘이 평균 대기시간이 가장 짧으나 실제적으로는 해당 작업이 얼마나 소요될지 알 수 없음. => 우선적으로 높은 우선순위를 부여하여 실행하되, 낮은 큐에 대기하고 있는 프로세스를 주기적으로 최상위 큐로 올려주는 부스팅을 통해 모든 프로세스가 균형있게 실행이 이루어지도록 장려.

### OS-044
Q. FIFO 스케쥴러는 정말 쓸모가 없는 친구일까요? 어떤 시나리오에 사용하면 좋을까요?

1) 배치시스템: 사용자와 상호작용이 없는 백그라운드 작업
2) 작업시간이 균일할 때; Convoy Effect
3) 임베디드 시스템

### OS-045
Q. 우리는 스케줄링 알고리즘을 "프로세스" 스케줄링 알고리즘이라고 부릅니다. 스레드는 다른 방식으로 스케줄링을 하나요?

동일하게 처리함. 현대 CPU의 스케줄링 기본단위는 스레드.

### OS-046
Q. 유저 스레드와 커널 스레드의 스케쥴링 알고리즘은 똑같을까요?

다름. 커널 스레드 -> Preemptive / 유저 스레드 -> Non-preemptive

---

## 📌 프로세스 동기화 문제

### OS-047
Q. 뮤텍스와 세마포어의 차이점은 무엇인가요?

| 구분 | 뮤텍스 (Mutex) | 세마포어 (Semaphore) |
|---|---|---|
| 동시 접근 | 오직 1개의 스레드만 가능 | N개 (설정된 개수만큼) 가능 |
| 소유권 | 있음 (Ownership) | 없음 (Signaling) |
| 작동 방식 | Lock / Unlock | Wait (P) / Signal (V) |

### OS-048
Q. 이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.

소유권의 유무. Mutex만이 소유권을 부여함.

### OS-049
Q. Lock을 얻기 위해 대기하는 프로세스들은 Spin Lock 기법을 사용할 수 있습니다. 이 방법의 장단점은 무엇인가요? 단점을 해결할 방법은 없을까요?

Busy waiting 방식으로, 스케줄러를 호출하지 않고 루프만 돌기 때문에 락을 얻는 속도가 매우 빠름. 하지만 lock을 기다리는 동안 CPU 낭비를 유발하고, 경쟁이 심할 경우 기아 현상이 발생할 수 있음. Sleep 방식으로, 잠금 해제 확인시 잠금 해제가 되지 않을 경우 wait상태로 fallback하는 hybrid 알고리즘을 통해 해결 가능.

### OS-050
Q. 뮤텍스와 세마포어 모두 커널이 관리하기 때문에, Lock을 얻고 방출하는 과정에서 시스템 콜을 호출해야 합니다. 이 방법의 장단점이 있을까요? 단점을 해결할 수 있는 방법은 없을까요?

- 문제점: 락의 획득/해제마다 무조건 시스템 콜을 사용하면, 불필요한 컨텍스트 스위칭이 발생하여 성능이 크게 저하됨.

- Futex: 시스템 콜의 오버헤드를 줄이기 위해 유저모드에서 플래그(변수)를 먼저 확인


### OS-051
Q. Deadlock 에 대해 설명해 주세요.

두 개 이상의 프로세스가 서로 가진 자원의 lock을 획득하기 위해 기다리며 무한 대기 하는 상태

### OS-052
Q. Deadlock 이 동작하기 위한 4가지 조건에 대해 설명해 주세요.

1) 상호배제
2) 점유 대기
3) 비선점
4) 순환대기

-> 두 프로세스가 상호 배제적 자원을 사용, 요구하며 점유 대기 상태에 있으며 비선점 알고리즘에 의해 자원을 할당 받기에 자원할당을 받기 위해서 순환대기상태에 놓여야함.

### OS-053
Q. 그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?

4가지 모두 AND 조건임. 하나라도 충족되지 않는다면 하나의 프로세스는 실행이 되어 자연스럽게 다른 프로세스 또한 요구하는 자원을 점유할 수 있게 되어 실행이 완료 됨.

### OS-054
Q. 어떤 방식으로 예방할 수 있을까요?

4가지 속성을 동시에 만족시키지 않도록 강제함.

### OS-055
Q. 왜 현대 OS는 Deadlock을 처리하지 않을까요?

가용가능한 자원의 크기가 늘었기에 데드락은 드물게 발생하므로, 이를 방지하기 위해 cost가 낭비될 가능성이 높음.

### OS-056
Q. Wait Free와 Lock Free를 비교해 주세요.

1. Lock-Free의 경우, 제한조건을 두지 않기에 최소 한 개의 프로세스 성공을 보장함.
2. Wait-Free의 경우, 개별 스레드의 Starvation이 발생하지 않음.

---

## 📌 컴파일

### OS-057
Q. 프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.

1. Preprocessing
- 헤더 파일 병합 및 매크로 구문 등을 처리

2. Compilation
- 전처리된 코드를 어셈플리어로 번역
- Syntax Error 분석

3. Assembly
- 0과 1로 된, 기계가 이해할 수 있는 object file로 변환

4. Linking
- 여러 개의 object file들과 라이브러리 함수를 하나로 합쳐 최종 실행 파일을 만듦.

### OS-058
Q. 링커와, 로더의 차이에 대해 설명해 주세요.
- 링커: 컴파일 타임 실행 전에 실행되며, 흩어져 있는 여러 개의 object file과 library file을 묶어서 하나의 실행 exe를 만듦.
- 로더: 런타임 시 실행되며, 하드디스크에 있는 실행파일을 RAM에 load하고, CPU가 실행할 수 있도록 주소를 배치함.

### OS-059
Q. 컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.

- 컴파일 언어: 소스 코드 전체를 미리 기계어로 번역해서 실행파일을 만듦.
- 인터프리터 언어: 실행할 때마다 소스코드를 한줄씩 읽어서 즉시 번역하며 실행

### OS-060
Q. JIT에 대해 설명해 주세요.

- 컴파일 언어와 인터프리터 언어의 장점을 섞은 하이브리드 방식. 프로그램 런타임에 기계어로 번역하는 기술. 처음에는 인터프리터방식을 사용하여 실행하되, 자주 쓰이는 코드에 대해서는 컴파일하여 메모리에 저장하는 캐싱 적용.

### OS-061
Q. 본인이 사용하는 언어는, 어떤식으로 컴파일 및 실행되는지 설명해 주세요.

- 파이썬. 인터프리터 방식으로 실행. 하지만 바이트코드로 컴파일 후 PVM이 인터프리팅하는 방식.

### OS-062
Q. Python 같은 언어는 CPython, Jython, PyPy등의 다양한 구현체가 있습니다. 각각은 어떤 차이가 있을까요? 또한, 실행되는 과정 또한 다를까요?

1. CPython (표준)

구현 언어: C언어

실행 방식: 소스 코드를 바이트코드로 변환 후, C로 작성된 가상머신이 한 줄씩 실행.

특징: JIT 컴파일러가 없음. 가장 널리 쓰이며 C 라이브러리 호환성이 좋음.

2. Jython

구현 언어: Java

실행 방식: 파이썬 코드를 **Java 바이트코드(.class)**로 컴파일하여 JVM 위에서 실행.

특징: JVM의 JIT 성능을 누릴 수 있고, Java 라이브러리를 그대로 가져다 쓸 수 있음.

3. PyPy

구현 언어: Python (RPython)

실행 방식: Tracing JIT 기술을 사용하여 실행 중에 자주 쓰이는 코드를 기계어로 최적화.

특징: CPython보다 평균 5~10배 빠릅니다. 순수 파이썬 코드 실행에 최적화되어 있음.

### OS-063
Q. 우리는 흔히 fork(), exec() 시스템 콜을 사용하여 프로세스를 적재할 수 있다고 배웠습니다. 로더의 역할은 이 시스템 콜과 상관있는 걸까요? 아니면 다른 방식으로 프로세스를 적재할 수 있는 건가요?

시스템 콜을 통해 트리거.
---